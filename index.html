<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="china">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    fastclick: false,
    lazyload: false,
    pangu: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Kopieren',
      copy_success: 'Kopiert',
      copy_failure: 'Kopieren fehlgeschlagen'
    }
  };
</script>

  <meta name="description" content="关于ssc学习python的艰辛之旅">
<meta name="keywords" content="ssc_python">
<meta property="og:type" content="website">
<meta property="og:title" content="Welcome to ssc bolg !">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Welcome to ssc bolg !">
<meta property="og:description" content="关于ssc学习python的艰辛之旅">
<meta property="og:locale" content="china">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Welcome to ssc bolg !">
<meta name="twitter:description" content="关于ssc学习python的艰辛之旅">





  
  
  <link rel="canonical" href="http://yoursite.com/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>Welcome to ssc bolg !</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="china">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Welcome to ssc bolg !</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">ssc bolg</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Navigationsleiste an/ausschalten">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archiv</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/07/破解js加密/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/08/07/破解js加密/" class="post-title-link" itemprop="url">破解js加密</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-08-07 20:07:27 / Geändert am: 21:17:26" itemprop="dateCreated datePublished" datetime="2019-08-07T20:07:27+08:00">2019-08-07</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="破解js加密数据"><a href="#破解js加密数据" class="headerlink" title="破解js加密数据"></a>破解js加密数据</h1><h2 id="有道词典js加密"><a href="#有道词典js加密" class="headerlink" title="有道词典js加密"></a>有道词典js加密</h2><p>爬取有道词典post请求中返回的数据信息是js加密中最为经典的加密类型。如图：</p>
<p><img src="/images/js%E5%8A%A0%E5%AF%861.jpg" alt="&quot;js加密&quot;"></p>
<p>其中以下有4个参数，salt是加盐的意思，这个是时间戳的意思。我们找到要提交的data数据中有一个时间戳，那我们就搜索时间戳的所有数据，如图：</p>
<p><img src="/images/js%E5%8A%A0%E5%AF%862.jpg" alt="&quot;js加密&quot;"></p>
<p>找到了对应的js文件，如图：</p>
<p><img src="/images/js%E5%8A%A0%E5%AF%863.jpg" alt="&quot;js加密&quot;"></p>
<p>分析js文件里的加密数据</p>
<p>通过Ctrl+F搜索salt（盐），我们找到了如下的数据进行进一步的分析。<br><img src="/images/js%E5%8A%A0%E5%AF%864.jpg" alt="&quot;js加密&quot;"></p>
<p>找到了如上的4个参数后开始分析参数里的字母所表示的含义，用户在获取到数据时必定会经过加密的js命令，所以在对应的js加密命令中打上一个断点。（断点的作用：在你打上断点之前的变量对应的值的信息都会进行一个显示）如图：</p>
<p><img src="/images/js%E5%8A%A0%E5%AF%865.jpg" alt="&quot;js加密&quot;"></p>
<p>分析好后就可以对post上传的data数据进行伪装了</p>
<p>有道词典源码，仅供参考：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">import requests,time,random,hashlib</span><br><span class="line"></span><br><span class="line">class YouDao():</span><br><span class="line">    </span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.url = r<span class="string">"http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule"</span></span><br><span class="line">        self.header = &#123;</span><br><span class="line">            <span class="string">"Accept"</span>:<span class="string">"application/json, text/javascript, */*; q=0.01"</span>,</span><br><span class="line">            <span class="string">"Accept-Encoding"</span>:<span class="string">"gzip, deflate"</span>,</span><br><span class="line">            <span class="string">"Accept-Language"</span>:<span class="string">"zh-CN,zh;q=0.9,en;q=0.8"</span>,</span><br><span class="line">            <span class="string">"Connection"</span>:<span class="string">"keep-alive"</span>,</span><br><span class="line">            <span class="string">"Content-Length"</span>:<span class="string">"238"</span>,</span><br><span class="line">            <span class="string">"Content-Type"</span>:<span class="string">"application/x-www-form-urlencoded; charset=UTF-8"</span>,</span><br><span class="line">            <span class="string">"Cookie"</span>:<span class="string">"OUTFOX_SEARCH_USER_ID=1691002130@10.169.0.84; OUTFOX_SEARCH_USER_ID_NCOO=1825077329.730029; _ga=GA1.2.1865132154.1563969328; DICT_UGC=be3af0da19b5c5e6aa4e17bd8d90b28a|; JSESSIONID=abcFCxWgGXFO2cg6S0RXw; ___rl__test__cookies=1565177117812"</span>,</span><br><span class="line">            <span class="string">"Host"</span>:<span class="string">"fanyi.youdao.com"</span>,</span><br><span class="line">            <span class="string">"Origin"</span>:<span class="string">"http://fanyi.youdao.com"</span>,</span><br><span class="line">            <span class="string">"Referer"</span>:<span class="string">"http://fanyi.youdao.com/"</span>,</span><br><span class="line">            <span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36"</span>,</span><br><span class="line">            <span class="string">"X-Requested-With"</span>:<span class="string">"XMLHttpRequest"</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    def md5(self,info):</span><br><span class="line">        <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        对sign进行md5加密</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        string = info.encode(<span class="string">"utf-8"</span>)</span><br><span class="line">        md5 = hashlib.md5(string).hexdigest()  <span class="comment"># 返回一个摘要 是一个32位的字符串</span></span><br><span class="line">        <span class="built_in">return</span> md5</span><br><span class="line"></span><br><span class="line">    def post_data(self,userinfo):</span><br><span class="line">        salt = str(time.time()*1000)+str(random.randint(0,9))</span><br><span class="line">        ts = str(time.time()*1000)</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">"i"</span>:userinfo,</span><br><span class="line">            <span class="string">"from"</span>:<span class="string">"AUTO"</span>,</span><br><span class="line">            <span class="string">"to"</span>:<span class="string">"AUTO"</span>,</span><br><span class="line">            <span class="string">"smartresult"</span>:<span class="string">"dict"</span>,</span><br><span class="line">            <span class="string">"client"</span>:<span class="string">"fanyideskweb"</span>,</span><br><span class="line">            <span class="string">"salt"</span>:salt,</span><br><span class="line">            <span class="string">"sign"</span>:self.md5(<span class="string">"fanyideskweb"</span>+userinfo+salt+<span class="string">"n%A-rKaT5fb[Gy?;N5@Tj"</span>),</span><br><span class="line">            <span class="string">"ts"</span>:ts,</span><br><span class="line">            <span class="string">"bv"</span>:<span class="string">"6bd43b532a04b6145782cfe65196ca4f"</span>,</span><br><span class="line">            <span class="string">"doctype"</span>:<span class="string">"json"</span>,</span><br><span class="line">            <span class="string">"version"</span>:<span class="string">"2.1"</span>,</span><br><span class="line">            <span class="string">"keyfrom"</span>:<span class="string">"fanyi.web"</span>,</span><br><span class="line">            <span class="string">"action"</span>:<span class="string">"FY_BY_REALTlME"</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        html = requests.post(url=self.url, headers=self.header, data=data)</span><br><span class="line">        <span class="built_in">return</span> html</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    user = input(<span class="string">"请输入要查询的内容："</span>)  <span class="comment">#可以是中文也可以是英文</span></span><br><span class="line">    youdao = YouDao()</span><br><span class="line">    info = youdao.post_data(user)</span><br><span class="line">    <span class="built_in">print</span>(info.text)</span><br></pre></td></tr></table></figure>

<h2 id="自制爬虫小工具"><a href="#自制爬虫小工具" class="headerlink" title="自制爬虫小工具"></a>自制爬虫小工具</h2><p>提供一个给请求头加“”的源码：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line"><span class="built_in">test</span> = <span class="string">""</span><span class="string">"  #test是放源data或源请求头中的信息</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">newlist = re.findall(r<span class="string">"(.*):\s(.*)"</span>,<span class="built_in">test</span>,re.M)</span><br><span class="line"><span class="keyword">for</span> dict <span class="keyword">in</span> newlist:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'"%s":"%s",'</span>%(dict[0],dict[1]))</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/06/爬取的数据写成exel表/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/08/06/爬取的数据写成exel表/" class="post-title-link" itemprop="url">爬取的数据写成exel表</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-08-06 19:13:07 / Geändert am: 19:57:25" itemprop="dateCreated datePublished" datetime="2019-08-06T19:13:07+08:00">2019-08-06</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="csv的基本使用介绍"><a href="#csv的基本使用介绍" class="headerlink" title="csv的基本使用介绍"></a>csv的基本使用介绍</h2><p>CSV(Comma-Separated Values)即逗号分隔值，可以用Excel打开查看。由于是纯文本，任何编辑器也都可打开。与Excel文件不同，CSV文件中：</p>
<ul>
<li>值没有类型，所有值都是字符串</li>
<li>不能指定字体颜色等样式</li>
<li>不能指定单元格的宽高，不能合并单元格</li>
<li>没有多个工作表</li>
<li>不能嵌入图像图表</li>
</ul>
<p>在CSV文件中，以<code>,</code>作为分隔符，分隔两个单元格。像这样<code>a,,c</code>表示单元格<code>a</code>和单元格<code>c</code>之间有个空白的单元格。依此类推。</p>
<p>不是每个逗号都表示单元格之间的分界。所以即使CSV是纯文本文件，也坚持使用专门的模块进行处理。Python内置了csv模块。</p>
<h2 id="从CSV文件中读取数据"><a href="#从CSV文件中读取数据" class="headerlink" title="从CSV文件中读取数据"></a>从CSV文件中读取数据</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import csv</span><br><span class="line"></span><br><span class="line">file = r<span class="string">"C:\Users\Administrator.SKY-20190217ZDF\Desktop\java.csv"</span></span><br><span class="line">with open(file,<span class="string">"r"</span>)as f:</span><br><span class="line">    files = csv.reader(f)</span><br><span class="line">    lists = list(files)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> lists:</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<p><img src="/images/csv%E6%95%88%E6%9E%9C%E5%9B%BE1.jpg" alt="&quot;最后的效果图&quot;"></p>
<p>前面的数字是行号，<strong>从1开始</strong>，可以用<code>reader.line_num</code>获取。<br>要注意的是，reader只能被遍历一次。由于reader是可迭代对象，可以使用<code>next</code>方法一次获取一行。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import csv</span><br><span class="line"></span><br><span class="line">filename = <span class="string">'F:/Jupyter Notebook/matplotlib_pygal_csv_json/sitka_weather_2014.csv'</span></span><br><span class="line">with open(filename,<span class="string">'r'</span>) as f:</span><br><span class="line">    reader = csv.reader(f)</span><br><span class="line">    <span class="comment"># 读取一行，下面的reader中已经没有该行了</span></span><br><span class="line">    head_row = next(reader)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">        <span class="comment"># 行号从2开始</span></span><br><span class="line">        <span class="built_in">print</span>(reader.line_num, row)</span><br></pre></td></tr></table></figure>

<h2 id="写数据到csv文件中-这个常用，写成exel表形式"><a href="#写数据到csv文件中-这个常用，写成exel表形式" class="headerlink" title="写数据到csv文件中(这个常用，写成exel表形式)"></a>写数据到csv文件中(这个常用，写成exel表形式)</h2><p>有reader可以读取，当然也有writer可以写入。一次写入一行，一次写入多行都可以。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import csv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用数字和字符串的数字都可以</span></span><br><span class="line">datas = [[<span class="string">'name'</span>, <span class="string">'age'</span>],</span><br><span class="line">         [<span class="string">'Bob'</span>, 14],</span><br><span class="line">         [<span class="string">'Tom'</span>, 23],</span><br><span class="line">        [<span class="string">'Jerry'</span>, <span class="string">'18'</span>]]</span><br><span class="line"></span><br><span class="line">with open(<span class="string">'example.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) as f:</span><br><span class="line">    writer = csv.writer(f)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> datas:</span><br><span class="line">        writer.writerow(row)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 还可以写入多行</span></span><br><span class="line">    writer.writerows(datas)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入多行</span></span><br><span class="line">with open(<span class="string">'java.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) as f:</span><br><span class="line">    writer = csv.writer(f)</span><br><span class="line">    writer.writerow([<span class="string">"工种"</span>,<span class="string">"薪酬"</span>,<span class="string">"学历"</span>,<span class="string">"公司名"</span>])</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> info:</span><br><span class="line">        writer.writerows(info)<span class="comment"># 还可以写入多行</span></span><br></pre></td></tr></table></figure>

<p>使用技巧：当写入exel表中时，第一行写入的是标题，第二行才开始是内容，这时我们可以分成两步，第一步先单独写入一行标题，如上，然后具体的数据内容就可以一次性写入多行了。也可以参考下面这种方式，通过字典的键值对进行写入exel表中。</p>
<h2 id="DictReader和DictWriter对象"><a href="#DictReader和DictWriter对象" class="headerlink" title="DictReader和DictWriter对象"></a>DictReader和DictWriter对象</h2><p>使用DictReader可以像操作字典那样获取数据，把表的第一行（一般是标头）作为key。可访问每一行中那个某个key对应的数据。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import csv</span><br><span class="line"></span><br><span class="line">filename = <span class="string">'F:/Jupyter Notebook/matplotlib_pygal_csv_json/sitka_weather_2014.csv'</span></span><br><span class="line">with open(filename,<span class="string">'r'</span>) as f:</span><br><span class="line">    reader = csv.DictReader(f)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">        <span class="comment"># Max TemperatureF是表第一行的某个数据，作为key</span></span><br><span class="line">        max_temp = row[<span class="string">'Max TemperatureF'</span>]</span><br><span class="line">        <span class="built_in">print</span>(max_temp)</span><br></pre></td></tr></table></figure>

<p>使用DictWriter类，可以写入字典形式的数据，同样键也是标头（表格第一行）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import csv</span><br><span class="line"></span><br><span class="line">headers = [<span class="string">'name'</span>, <span class="string">'age'</span>]</span><br><span class="line"></span><br><span class="line">datas = [&#123;<span class="string">'name'</span>:<span class="string">'Bob'</span>, <span class="string">'age'</span>:23&#125;,</span><br><span class="line">        &#123;<span class="string">'name'</span>:<span class="string">'Jerry'</span>, <span class="string">'age'</span>:44&#125;,</span><br><span class="line">        &#123;<span class="string">'name'</span>:<span class="string">'Tom'</span>, <span class="string">'age'</span>:15&#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">with open(<span class="string">'example.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) as f:</span><br><span class="line">    <span class="comment"># 标头在这里传入，作为第一行数据</span></span><br><span class="line">    writer = csv.DictWriter(f, fieldnames=headers)</span><br><span class="line">    writer.writeheader()</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> datas:</span><br><span class="line">        writer.writerow(row)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 还可以写入多行</span></span><br><span class="line">    writer.writerows(datas)</span><br></pre></td></tr></table></figure>


          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/02/APP爬取豆果美食/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/08/02/APP爬取豆果美食/" class="post-title-link" itemprop="url">APP爬取豆果美食</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-08-02 20:20:18 / Geändert am: 21:33:39" itemprop="dateCreated datePublished" datetime="2019-08-02T20:20:18+08:00">2019-08-02</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="爬取移动端豆果美食"><a href="#爬取移动端豆果美食" class="headerlink" title="爬取移动端豆果美食"></a>爬取移动端豆果美食</h1><p>首先我们爬取网页的一级分类、二级分类、三级分类，如图：</p>
<p><img src="/images/%E8%B1%86%E6%9E%9C%E7%BE%8E%E9%A3%9F1.jpg" alt="&quot;找到对应的分类&quot;"></p>
<p>查看fiddler中对应的API，找到对应的放回数据，点击菜谱分类查看对应的url</p>
<p><img src="/images/%E8%B1%86%E6%9E%9C%E7%BE%8E%E9%A3%9F2.jpg" alt="&quot;找到对应的API接口&quot;"></p>
<p>因为是post请求，所以我们要先提交data数据给服务器，服务器再返回json数据给我们，如图：</p>
<p><img src="/images/%E8%B1%86%E6%9E%9C%E7%BE%8E%E9%A3%9F3.jpg" alt="&quot;找到对应的data数据&quot;"></p>
<p>执行代码：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">import requests,json</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://api.douguo.net/recipe/flatcatalogs"</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">"client"</span>:<span class="string">"4"</span>,<span class="string">"_session"</span>:<span class="string">"1564736616075866174011442080"</span>,<span class="string">"v"</span>:<span class="string">"1564131145"</span>,<span class="string">"_vs"</span>:<span class="string">"2305"</span></span><br><span class="line">&#125;</span><br><span class="line">header = &#123;</span><br><span class="line">    <span class="string">"client"</span>: <span class="string">"4"</span>,</span><br><span class="line">    <span class="string">"version"</span>: <span class="string">"6942.6"</span>,</span><br><span class="line">    <span class="string">"device"</span>: <span class="string">"MI 5"</span>,</span><br><span class="line">    <span class="string">"sdk"</span>: <span class="string">"19,4.4.2"</span>,</span><br><span class="line">    <span class="string">"imei"</span>: <span class="string">"866174011442080"</span>,</span><br><span class="line">    <span class="string">"channel"</span>: <span class="string">"360sc"</span>,</span><br><span class="line">    <span class="string">"mac"</span>: <span class="string">"2C:D0:5A:F9:A9:77"</span>,</span><br><span class="line">    <span class="string">"resolution"</span>: <span class="string">"1280*720"</span>,</span><br><span class="line">    <span class="string">"dpi"</span>: <span class="string">"1.5"</span>,</span><br><span class="line">    <span class="string">"android-id"</span>: <span class="string">"12cd05af9a977969"</span>,</span><br><span class="line">    <span class="string">"pseudo-id"</span>: <span class="string">"5af9a97796912cd0"</span>,</span><br><span class="line">    <span class="string">"brand"</span>: <span class="string">"Xiaomi"</span>,</span><br><span class="line">    <span class="string">"scale"</span>: <span class="string">"1.5"</span>,</span><br><span class="line">    <span class="string">"timezone"</span>: <span class="string">"28800"</span>,</span><br><span class="line">    <span class="string">"language"</span>: <span class="string">"zh"</span>,</span><br><span class="line">    <span class="string">"cns"</span>: <span class="string">"3"</span>,</span><br><span class="line">    <span class="string">"carrier"</span>: <span class="string">"CMCC"</span>,</span><br><span class="line">    <span class="string">"imsi"</span>: <span class="string">"460071442089024"</span>,</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Linux; Android 4.4.2; MI 5  Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/30.0.0.0 Mobile Safari/537.36"</span>,</span><br><span class="line">    <span class="string">"act-code"</span>: <span class="string">"3985fc0a9fe4a1c8e8ca0d004ed6853e"</span>,</span><br><span class="line">    <span class="string">"act-timestamp"</span>: <span class="string">"1564136461"</span>,</span><br><span class="line">    <span class="string">"uuid"</span>: <span class="string">"a3eee28e-5f51-455c-999a-135442e07b88"</span>,</span><br><span class="line">    <span class="string">"newbie"</span>: <span class="string">"1"</span>,</span><br><span class="line">    <span class="string">"reach"</span>: <span class="string">"10000"</span>,</span><br><span class="line">    <span class="string">"lon"</span>: <span class="string">"116.568253"</span>,</span><br><span class="line">    <span class="string">"lat"</span>: <span class="string">"27.997877"</span>,</span><br><span class="line">    <span class="string">"cid"</span>: <span class="string">"361000"</span>,</span><br><span class="line">    <span class="string">"Content-Type"</span>: <span class="string">"application/x-www-form-urlencoded; charset=utf-8"</span>,</span><br><span class="line">    <span class="string">"Accept-Encoding"</span>: <span class="string">"gzip, deflate"</span>,</span><br><span class="line">    <span class="string">"Connection"</span>: <span class="string">"Keep-Alive"</span>,</span><br><span class="line">    <span class="string">"Cookie"</span>: <span class="string">"duid=60587649"</span>,</span><br><span class="line">    <span class="string">"Host"</span>: <span class="string">"api.douguo.net"</span>,</span><br><span class="line">    <span class="string">"Content-Length"</span>: <span class="string">"68"</span>,</span><br><span class="line">&#125;</span><br><span class="line">mains = requests.post(headers=header,data=data,url=url)</span><br><span class="line">info = json.loads(mains.text)   <span class="comment">#建议这里先打印一下看看info是一个什么类型，需要for几次等</span></span><br><span class="line">user_list = []</span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> info[<span class="string">"result"</span>][<span class="string">"cs"</span>]:</span><br><span class="line">    <span class="keyword">for</span> small_title <span class="keyword">in</span> title[<span class="string">"cs"</span>]:</span><br><span class="line">        l_name = []</span><br><span class="line">        <span class="keyword">for</span> infos <span class="keyword">in</span> small_title[<span class="string">"cs"</span>]:</span><br><span class="line">            l_name.append(infos[<span class="string">"name"</span>])</span><br><span class="line">        <span class="keyword">if</span> small_title[<span class="string">"name"</span>] is <span class="string">""</span>:</span><br><span class="line">            small_title[<span class="string">"name"</span>] = <span class="string">"此实物没有分类"</span></span><br><span class="line">        user = &#123;small_title[<span class="string">"name"</span>]: l_name&#125;</span><br><span class="line">        users = &#123;title[<span class="string">"name"</span>]:user&#125;</span><br><span class="line">        user_list.append(users)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> user_list:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<p>代码执行的效果图：</p>
<p><img src="/images/%E8%B1%86%E6%9E%9C%E7%BE%8E%E9%A3%9F4.jpg" alt="&quot;最后返回的数据&quot;"></p>
<h1 id="爬取app里的详细信息"><a href="#爬取app里的详细信息" class="headerlink" title="爬取app里的详细信息"></a>爬取app里的详细信息</h1><p>爬取分类里的每一个菜系中的菜名、作者、做过人数等，如图：</p>
<p><img src="/images/%E8%B1%86%E6%9E%9C%E7%BE%8E%E9%A3%9F5.jpg" alt="&quot;&quot;"></p>
<p>在fiddler中找到对应的API，进行伪装请求获取json数据，如图：</p>
<p><img src="/images/%E8%B1%86%E6%9E%9C%E7%BE%8E%E9%A3%9F6.jpg" alt="&quot;获取到对应的API&quot;"></p>
<p>既然找到了对应的API接口，就开始进行代码编写</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import requests,json</span><br><span class="line"></span><br><span class="line">class APP():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.header = &#123;</span><br><span class="line">        <span class="string">"client"</span>: <span class="string">"4"</span>,</span><br><span class="line">        <span class="string">"version"</span>: <span class="string">"6942.6"</span>,</span><br><span class="line">        <span class="string">"device"</span>: <span class="string">"MI 5"</span>,</span><br><span class="line">        <span class="string">"sdk"</span>: <span class="string">"19,4.4.2"</span>,</span><br><span class="line">        <span class="string">"imei"</span>: <span class="string">"866174011442080"</span>,</span><br><span class="line">        <span class="string">"channel"</span>: <span class="string">"360sc"</span>,</span><br><span class="line">        <span class="string">"mac"</span>: <span class="string">"2C:D0:5A:F9:A9:77"</span>,</span><br><span class="line">        <span class="string">"resolution"</span>: <span class="string">"1280*720"</span>,</span><br><span class="line">        <span class="string">"dpi"</span>: <span class="string">"1.5"</span>,</span><br><span class="line">        <span class="string">"android-id"</span>: <span class="string">"12cd05af9a977969"</span>,</span><br><span class="line">        <span class="string">"pseudo-id"</span>: <span class="string">"5af9a97796912cd0"</span>,</span><br><span class="line">        <span class="string">"brand"</span>: <span class="string">"Xiaomi"</span>,</span><br><span class="line">        <span class="string">"scale"</span>: <span class="string">"1.5"</span>,</span><br><span class="line">        <span class="string">"timezone"</span>: <span class="string">"28800"</span>,</span><br><span class="line">        <span class="string">"language"</span>: <span class="string">"zh"</span>,</span><br><span class="line">        <span class="string">"cns"</span>: <span class="string">"3"</span>,</span><br><span class="line">        <span class="string">"carrier"</span>: <span class="string">"CMCC"</span>,</span><br><span class="line">        <span class="string">"imsi"</span>: <span class="string">"460071442089024"</span>,</span><br><span class="line">        <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Linux; Android 4.4.2; MI 5  Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/30.0.0.0 Mobile Safari/537.36"</span>,</span><br><span class="line">        <span class="string">"act-code"</span>: <span class="string">"3985fc0a9fe4a1c8e8ca0d004ed6853e"</span>,</span><br><span class="line">        <span class="string">"act-timestamp"</span>: <span class="string">"1564136461"</span>,</span><br><span class="line">        <span class="string">"uuid"</span>: <span class="string">"a3eee28e-5f51-455c-999a-135442e07b88"</span>,</span><br><span class="line">        <span class="string">"newbie"</span>: <span class="string">"1"</span>,</span><br><span class="line">        <span class="string">"reach"</span>: <span class="string">"10000"</span>,</span><br><span class="line">        <span class="string">"lon"</span>: <span class="string">"116.568253"</span>,</span><br><span class="line">        <span class="string">"lat"</span>: <span class="string">"27.997877"</span>,</span><br><span class="line">        <span class="string">"cid"</span>: <span class="string">"361000"</span>,</span><br><span class="line">        <span class="string">"Content-Type"</span>: <span class="string">"application/x-www-form-urlencoded; charset=utf-8"</span>,</span><br><span class="line">        <span class="string">"Accept-Encoding"</span>: <span class="string">"gzip, deflate"</span>,</span><br><span class="line">        <span class="string">"Connection"</span>: <span class="string">"Keep-Alive"</span>,</span><br><span class="line">        <span class="string">"Cookie"</span>: <span class="string">"duid=60587649"</span>,</span><br><span class="line">        <span class="string">"Host"</span>: <span class="string">"api.douguo.net"</span>,</span><br><span class="line">        <span class="string">"Content-Length"</span>: <span class="string">"96"</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    def get_url(self,food):</span><br><span class="line">        self.data = &#123;</span><br><span class="line">            <span class="string">"client"</span>: <span class="string">"4"</span>, <span class="string">"_session"</span>: <span class="string">"1564736616075866174011442080"</span>, <span class="string">"keyword"</span>: <span class="string">"&#123;&#125;"</span>.format(food), <span class="string">"order"</span>: <span class="string">"0"</span>, <span class="string">"_vs"</span>: <span class="string">"400"</span>,<span class="string">"type"</span>: <span class="string">"0"</span></span><br><span class="line">        &#125;</span><br><span class="line">        userList = &#123;<span class="string">"con"</span>:[]&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(0,100,20):   <span class="comment">#通过for循环获取到5页的内容</span></span><br><span class="line">            url = <span class="string">"http://api.douguo.net/recipe/v2/search/%d/20"</span>%(i)</span><br><span class="line">            mains = requests.post(url=url, data=self.data, headers=self.header)</span><br><span class="line">            info = json.loads(mains.text)</span><br><span class="line">            userList[<span class="string">"con"</span>].append(info)</span><br><span class="line">        <span class="built_in">return</span> userList</span><br><span class="line"></span><br><span class="line">    def get_info(self,info):</span><br><span class="line">        userList = []</span><br><span class="line">        <span class="keyword">for</span> con <span class="keyword">in</span> info[<span class="string">"con"</span>]:</span><br><span class="line">            <span class="keyword">for</span> info <span class="keyword">in</span> con[<span class="string">"result"</span>][<span class="string">"list"</span>]:</span><br><span class="line">                users = &#123;<span class="string">"菜名"</span>: info[<span class="string">'r'</span>][<span class="string">'n'</span>], <span class="string">"作者"</span>: info[<span class="string">'r'</span>][<span class="string">'an'</span>], <span class="string">"评分"</span>: info[<span class="string">'r'</span>][<span class="string">'rate'</span>],<span class="string">"做过人数"</span>: info[<span class="string">'r'</span>][<span class="string">'recommendation_tag'</span>]&#125;</span><br><span class="line">                userList.append(users)</span><br><span class="line">        <span class="built_in">return</span> userList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    user = input(<span class="string">"请输入食材："</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(user))</span><br><span class="line">    app = APP()</span><br><span class="line">    info = app.get_url(user)</span><br><span class="line">    get_info = app.get_info(info)</span><br><span class="line">    <span class="keyword">for</span>  i <span class="keyword">in</span> get_info:</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<h2 id="注意代码中输入的食材必须是app页面中有的食材，不然爬取不了"><a href="#注意代码中输入的食材必须是app页面中有的食材，不然爬取不了" class="headerlink" title="注意代码中输入的食材必须是app页面中有的食材，不然爬取不了"></a>注意代码中输入的食材必须是app页面中有的食材，不然爬取不了</h2><p>最终的效果图如下：</p>
<p><img src="/images/%E8%B1%86%E6%9E%9C%E7%BE%8E%E9%A3%9F7.jpg" alt="&quot;最终效果图&quot;"></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/01/爬取app移动端小说/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/08/01/爬取app移动端小说/" class="post-title-link" itemprop="url">爬取app移动端小说</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-08-01 15:05:42 / Geändert am: 15:51:45" itemprop="dateCreated datePublished" datetime="2019-08-01T15:05:42+08:00">2019-08-01</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="爬取移动端17K小说"><a href="#爬取移动端17K小说" class="headerlink" title="爬取移动端17K小说"></a>爬取移动端17K小说</h1><p>在爬虫的环境变量都配置好后，开始进行爬取移动端信息。</p>
<h2 id="查看fiddler抓包工具，找对应的API接口-爬取小说分类"><a href="#查看fiddler抓包工具，找对应的API接口-爬取小说分类" class="headerlink" title="查看fiddler抓包工具，找对应的API接口,爬取小说分类"></a>查看fiddler抓包工具，找对应的API接口,爬取小说分类</h2><p>先打开17K小说这个软件，此时我们会发现有许多的请求，这是前段页面向后台服务器进行的请求链接，要从众多的请求中找到对应想要的数据信息，如图：</p>
<p>我们先爬取分类里的男女生分类、个性定制、与出版社等信息</p>
<p><img src="/images/%E5%B0%8F%E8%AF%B4%E7%88%AC%E5%8F%961.jpg" alt="&quot;找到对应的API接口&quot;"></p>
<p>找到了对应的数据信息与url，我们就可以请求url来获取json数据</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import requests,json,re</span><br><span class="line">class XiaoShuo():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.url = r<span class="string">"http://api.17k.com/v2/book/category?icon_type=2&amp;data_type=1&amp;book_num=1&amp;app_key=4037465544&amp;_versions=970&amp;client_type=1&amp;_filter_data=1&amp;channel=2&amp;merchant=CPS-yeshen00001&amp;_access_version=2&amp;cps=CPS-yeshen "</span></span><br><span class="line">        self.header = &#123;</span><br><span class="line">            <span class="comment"># 'Connection: close</span></span><br><span class="line">            <span class="string">'Host'</span>: <span class="string">'api.17k.com'</span>,</span><br><span class="line">            <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip'</span>,</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'okhttp/3.2.0'</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    def get_list(self):</span><br><span class="line">        <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        所有书籍分类</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        '</span><span class="string">''</span></span><br><span class="line">        main = requests.get(self.url, headers=self.header)</span><br><span class="line">        content = json.loads(main.text)</span><br><span class="line">        user_list = []</span><br><span class="line">        <span class="keyword">for</span> info <span class="keyword">in</span> content[<span class="string">"data"</span>]:</span><br><span class="line">            <span class="keyword">for</span> con <span class="keyword">in</span> info[<span class="string">"child_node"</span>]:</span><br><span class="line">                title = con[<span class="string">"name"</span>]</span><br><span class="line">                read_num = con[<span class="string">"total_book"</span>]</span><br><span class="line">                user_list.append(&#123;title:<span class="string">'%s'</span>%read_num+<span class="string">'册'</span>&#125;)</span><br><span class="line">        <span class="built_in">return</span> user_list</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    xiaoshuo = XiaoShuo()</span><br><span class="line">    con = xiaoshuo.get_list()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> con:</span><br><span class="line">        <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<p>print出来的i结果如图：</p>
<p><img src="/images/%E5%B0%8F%E8%AF%B4%E7%88%AC%E5%8F%962.jpg" alt="&quot;爬取到小说分类效果图&quot;"></p>
<h2 id="爬取小说数据内容"><a href="#爬取小说数据内容" class="headerlink" title="爬取小说数据内容"></a>爬取小说数据内容</h2><p>开始爬取小说的正式内容</p>
<p><img src="/images/%E5%B0%8F%E8%AF%B4%E7%88%AC%E5%8F%963.jpg" alt="&quot;爬取到小说content数据的url&quot;"></p>
<p>找到了对应的url后就可以在pycharm上进行编码，请求对应的数据</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import requests,json,re</span><br><span class="line"></span><br><span class="line">class XiaoShuo():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.url = r<span class="string">"http://api.17k.com/v2/book/1859126/chapter/25186231/content?app_key=4037465544&amp;_versions=970&amp;client_type=1&amp;_filter_data=1&amp;channel=2&amp;merchant=CPS-yeshen00001&amp;_access_version=2&amp;cps=CPS-yeshen"</span></span><br><span class="line">        self.header = &#123;</span><br><span class="line">            <span class="string">'Host'</span>: <span class="string">'api.17k.com'</span>,</span><br><span class="line">            <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip'</span>,</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'okhttp/3.2.0'</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    def get_book_info(self):</span><br><span class="line">        mains = requests.get(self.url,self.header)</span><br><span class="line">        con = json.loads(mains.text)</span><br><span class="line">        <span class="built_in">return</span> con[<span class="string">'data'</span>][<span class="string">'content'</span>]</span><br><span class="line"></span><br><span class="line">    def save(self,con):</span><br><span class="line">        with open(r<span class="string">'./app小说内容.txt'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>)as f:</span><br><span class="line">            f.write(con)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    xiaoshuo = XiaoShuo()</span><br><span class="line">    info = xiaoshuo.get_book_info()</span><br><span class="line">    xiaoshuo.save(info)</span><br></pre></td></tr></table></figure>

<p>最后效果如图：</p>
<p><img src="/images/%E5%B0%8F%E8%AF%B4%E7%88%AC%E5%8F%964.jpg" alt="&quot;爬取到小说内容&quot;"></p>
<p>此时的爬取小说内容就已经完成了</p>
<h3 id="如果要爬取整个小说的所有内容则需要对自己请求的url接口进行分析，每一页对应的小说book-id不同，返回的数据都不同，可以把对所有的book-id爬取下来后拼接到url中，再对这个全新的url进行访问爬取数据。"><a href="#如果要爬取整个小说的所有内容则需要对自己请求的url接口进行分析，每一页对应的小说book-id不同，返回的数据都不同，可以把对所有的book-id爬取下来后拼接到url中，再对这个全新的url进行访问爬取数据。" class="headerlink" title="如果要爬取整个小说的所有内容则需要对自己请求的url接口进行分析，每一页对应的小说book_id不同，返回的数据都不同，可以把对所有的book_id爬取下来后拼接到url中，再对这个全新的url进行访问爬取数据。"></a>如果要爬取整个小说的所有内容则需要对自己请求的url接口进行分析，每一页对应的小说book_id不同，返回的数据都不同，可以把对所有的book_id爬取下来后拼接到url中，再对这个全新的url进行访问爬取数据。</h3><p><img src="/images/%E5%B0%8F%E8%AF%B4%E7%88%AC%E5%8F%965.jpg" alt="&quot;爬取所有的小说内容&quot;"></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/01/APP信息爬取(环境部署)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/08/01/APP信息爬取(环境部署)/" class="post-title-link" itemprop="url">APP信息爬取</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-08-01 13:47:34 / Geändert am: 15:01:45" itemprop="dateCreated datePublished" datetime="2019-08-01T13:47:34+08:00">2019-08-01</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="下载抓包工具"><a href="#下载抓包工具" class="headerlink" title="下载抓包工具"></a>下载抓包工具</h2><h3 id="Fiddler抓包工具"><a href="#Fiddler抓包工具" class="headerlink" title="Fiddler抓包工具"></a>Fiddler抓包工具</h3><p>Fiddler（中文名称：小提琴）是一个HTTP的调试代理，以代理服务器的方式，监听系统的Http网络数据流动，Fiddler也可以让你检查所有的HTTP通讯，设置断点，以及Fiddle所有的“进出”的数据（我一般用来抓包）,Fiddler还包含一个简单却功能强大的基于JScript .NET事件脚本子系统，它可以支持众多的HTTP调试任务。</p>
<h3 id="青花瓷抓包工具"><a href="#青花瓷抓包工具" class="headerlink" title="青花瓷抓包工具"></a>青花瓷抓包工具</h3><p>Charles是一款代理服务器，通过将自己设置成系统（电脑或者浏览器）的网络访问代理服务器，然后截取请求和请求结果进行分析抓包。<br>Charles是专门对app移动端进行的抓包工具，是要进行收费的</p>
<h2 id="app抓包环境"><a href="#app抓包环境" class="headerlink" title="app抓包环境"></a>app抓包环境</h2><p>这是我采用的是fiddler工具进行抓包，fiddler不仅可以对移动端进行抓包，也可以对PC端进行抓包，比较方便，因此我采用fiddler进行抓包。这里就不介绍怎么安装了。</p>
<p>对app爬取的环境配置</p>
<p><img src="/images/fiddler1.jpg" alt="&quot;fiddler配置1&quot;"></p>
<p>选中图中的工具–选项 把要勾的都勾选上（如下图）</p>
<p><img src="/images/fiddler2.jpg" alt="&quot;fiddler配置2&quot;"></p>
<p><img src="/images/fiddler3.jpg" alt="&quot;fiddler配置3&quot;"></p>
<p><img src="/images/fiddler4.jpg" alt="&quot;fiddler配置4&quot;"></p>
<p>以上操作设置好了fiddler的app环境配置，接下来我们下载一个模拟器在模拟端进行手机app爬取信息</p>
<h2 id="模拟器的安装"><a href="#模拟器的安装" class="headerlink" title="模拟器的安装"></a>模拟器的安装</h2><p>在网上有许多模拟器的软件，这里就不一一介绍了，我们现在采用夜神模拟器的安装</p>
<h2 id="夜神模拟器配置"><a href="#夜神模拟器配置" class="headerlink" title="夜神模拟器配置"></a>夜神模拟器配置</h2><p>安装就不介绍了，这个就介绍夜神模拟器中的证书与fiddler之间建立一个链接，当用户进行app爬取信息时，让网络的流量先通过fiddler抓包工具，通过fiddler再发送流量，而接受回来的流量也是先经过fiddler抓包工具在把数据的内容发送给app移动端。所以fiddler充当的身份相当于一个中间人的身份。</p>
<p>对模拟器中的WiFi设置，如图：</p>
<p><img src="/images/fiddler5.jpg" alt="&quot;fiddler配置5&quot;"></p>
<p>模拟器的证书安装：<br>参考：<a href="https://www.cnblogs.com/Supperlitt/p/6816256.html" target="_blank" rel="noopener">https://www.cnblogs.com/Supperlitt/p/6816256.html</a></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/30/对爬取的信息做可视化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/30/对爬取的信息做可视化/" class="post-title-link" itemprop="url">对爬取的信息做可视化</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-30 22:00:14 / Geändert am: 22:28:16" itemprop="dateCreated datePublished" datetime="2019-07-30T22:00:14+08:00">2019-07-30</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="信息数据的可视化介绍"><a href="#信息数据的可视化介绍" class="headerlink" title="信息数据的可视化介绍"></a>信息数据的可视化介绍</h2><p>做数据分析一般用到的三个包matplotlib、numpy、pandas<br>matplotlib是专门对爬取的数据做一个折线图、扇形图、条形图等。一般是结合numpy一起使用的。<br>numpy是NumPy是使用Python进行科学计算的基础包，提供高性能的矩阵运算。<br>Pandas是一个强大的分析结构化数据的工具集；它的使用基础是Numpy（提供高性能的矩阵运算）；用于数据挖掘和数据分析，同时也提供数据清洗功能。<br>对numpy而我一般用于对csv文件的读取，没有细致的研究</p>
<h2 id="可视化matplotlib用法"><a href="#可视化matplotlib用法" class="headerlink" title="可视化matplotlib用法"></a>可视化matplotlib用法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd  <span class="comment">#对数据的选取操作</span></span><br><span class="line"></span><br><span class="line">path = r<span class="string">"C:\Users\Administrator.SKY-20190217ZDF\Desktop\java.csv"</span></span><br><span class="line">users_info = pd.read_csv(path,encoding=<span class="string">"gbk"</span>,sep=<span class="string">","</span>)  <span class="comment">#查询到csv中的所有数据，并存在名为user_info的变量名内</span></span><br><span class="line"><span class="built_in">print</span>(users_info.head(10))  <span class="comment">#查看数据的前10行</span></span><br><span class="line"><span class="built_in">print</span>(users_info.tail(10))   <span class="comment">#查看数据后10行</span></span><br><span class="line"><span class="built_in">print</span>(users_info.shape)  <span class="comment">#查看数据中有几列几行，并用数组类型包裹</span></span><br><span class="line"><span class="built_in">print</span>(users_info.columns)  <span class="comment">#查看数据中全部列的名称</span></span><br><span class="line"><span class="built_in">print</span>(users_info.dtypes)   <span class="comment">#查看数据类型</span></span><br><span class="line"><span class="built_in">print</span>(users_info.index)  <span class="comment">#查看数据索引</span></span><br><span class="line"><span class="built_in">print</span>(users_info.sample(n=5))  <span class="comment">#随机抽取5行数据</span></span><br><span class="line"><span class="built_in">print</span>(users_info.sample(frac=0.3))  <span class="comment">#按照固定的比例去随机选取，在user_info的总数量上随机选取30%的信息</span></span><br><span class="line"><span class="built_in">print</span>(users_info.describe())</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------查询列信息--------</span></span><br><span class="line"><span class="built_in">print</span>(users_info[<span class="string">"学历"</span>])  <span class="comment">#获取其中一列数据</span></span><br><span class="line"><span class="built_in">print</span>(users_info[[<span class="string">"工种"</span>,<span class="string">'学历'</span>]])  <span class="comment">#获取多列的数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------增加列信息---------</span></span><br><span class="line">users_info[<span class="string">"福利"</span>] = <span class="string">"暂无"</span>  <span class="comment">#添加多一列，列头名为福利，下面的每一条福利信息都是暂时</span></span><br><span class="line"><span class="built_in">print</span>(users_info.columns)</span><br><span class="line"><span class="built_in">print</span>(users_info)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(users_info.iloc[0])  <span class="comment">#通过iloc获取到指定第几行的数据</span></span><br><span class="line"><span class="built_in">print</span>(users_info.iloc[1][<span class="string">'学历'</span>])  <span class="comment">#获取到第一行中的所有数据后只显示学历的字段值</span></span><br><span class="line"><span class="built_in">print</span>(users_info.iloc[5:10])   <span class="comment">#获取到5到10的所有信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------统计函数--------</span></span><br><span class="line"><span class="built_in">print</span>(users_info[<span class="string">'薪酬'</span>].mean())</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------解决图像为口或是负号的问题----------</span></span><br><span class="line">plt.rcParams[<span class="string">"font.sans-serif"</span>] = [<span class="string">'simhei'</span>]  <span class="comment"># 修改默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = False  <span class="comment"># 解决保存图像是负号'-'显示为方块的问题</span></span><br></pre></td></tr></table></figure>

<h2 id="条形图与扇形图的用法"><a href="#条形图与扇形图的用法" class="headerlink" title="条形图与扇形图的用法"></a>条形图与扇形图的用法</h2><p>对java与python的招聘数据分析</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">path1 = r<span class="string">"C:\Users\Administrator.SKY-20190217ZDF\Desktop\java.csv"</span></span><br><span class="line">path2 = r<span class="string">"C:\Users\Administrator.SKY-20190217ZDF\Desktop\python.csv"</span></span><br><span class="line">data_python = pd.read_csv(path2,encoding=<span class="string">"gbk"</span>)</span><br><span class="line">data_java = pd.read_csv(path1,encoding=<span class="string">"gbk"</span>)</span><br><span class="line">plt.figure(num=1)</span><br><span class="line">count1 = data_python[<span class="string">'薪酬'</span>].value_counts().plot(kind=<span class="string">"bar"</span>,rot=0) <span class="comment">#bar是条形图，barh是横轴条形图</span></span><br><span class="line">python_money = data_python[<span class="string">"薪酬"</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">count2 = data_java[<span class="string">"薪酬"</span>].value_counts().plot(kind=<span class="string">"pie"</span>,autopct=<span class="string">"%1.2f%%"</span>,explode=np.linspace(0,0.5,14))  <span class="comment">#pie是画饼形图autopct是生成扇形图的百分比,explode爆炸效果参数解析("圆心"，"离圆心的距离","一共有多少个元素")</span></span><br><span class="line">java_money = data_java[<span class="string">"薪酬"</span>]</span><br><span class="line"><span class="built_in">print</span>(java_money)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>接下来绘图保存：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(train_X, train_Y, <span class="string">'ro'</span>, label=<span class="string">'Original data'</span>)</span><br><span class="line">plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=<span class="string">'Fitted line'</span>)</span><br><span class="line">plt.savefig(<span class="string">"examples.jpg"</span>)  <span class="comment">#通过savefig进行对分析好的数据进行保存到本地</span></span><br><span class="line">--------------------- </span><br><span class="line">作者：Bicelove </span><br><span class="line">来源：CSDN </span><br><span class="line">原文：https://blog.csdn.net/u010555688/article/details/64467864</span><br></pre></td></tr></table></figure>

<p>效果图如下：<br><img src="/images/python%E5%B0%B1%E4%B8%9A%E5%9B%BE.jpg" alt="&quot;python就业地区分布图&quot;"><br>用hexo上传图片这个研究了挺久的，下次把这个上传图片的笔记补上<br>hexo上传图片的参考链接：<a href="https://yanyinhong.github.io/2017/05/02/How-to-insert-image-in-hexo-post/" target="_blank" rel="noopener">https://yanyinhong.github.io/2017/05/02/How-to-insert-image-in-hexo-post/</a></p>
<h2 id="51job视图可视化"><a href="#51job视图可视化" class="headerlink" title="51job视图可视化"></a>51job视图可视化</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">path1 = r<span class="string">"C:\Users\Administrator.SKY-20190217ZDF\Desktop\python.csv"</span></span><br><span class="line">fig=plt.figure(num=1,figsize=(15,8),dpi=80)</span><br><span class="line">python_job = pd.read_csv(path1,encoding=<span class="string">"gbk"</span>)</span><br><span class="line">count = python_job[<span class="string">"地区"</span>].value_counts().plot()</span><br><span class="line"><span class="comment"># python_money = python_job["地区"]</span></span><br><span class="line"><span class="comment"># 修改默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">"font.sans-serif"</span>] = [<span class="string">'simhei'</span>]  <span class="comment"># 修改默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = False  <span class="comment"># 解决保存图像是负号'-'显示为方块的问题</span></span><br><span class="line"><span class="comment"># plt.savefig(r'C:\Users\Administrator.SKY-20190217ZDF\Desktop\python就业分布图.png')</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/28/scrapy框架/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/28/scrapy框架/" class="post-title-link" itemprop="url">scrapy框架</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-28 12:53:18" itemprop="dateCreated datePublished" datetime="2019-07-28T12:53:18+08:00">2019-07-28</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-07-29 11:13:37" itemprop="dateModified" datetime="2019-07-29T11:13:37+08:00">2019-07-29</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="scrapy框架工作结构"><a href="#scrapy框架工作结构" class="headerlink" title="scrapy框架工作结构"></a>scrapy框架工作结构</h2><p>scrapy框架运行流程</p>
<p>1、调度器把requests–&gt;引擎–&gt;下载中间件—&gt;下载器<br>2、下载器发送请求，获取响应—-&gt;下载中间件—-&gt;引擎—&gt;爬虫中间件—&gt;爬虫<br>3、爬虫提取url地址，组装成request对象—-&gt;爬虫中间件—&gt;引擎—&gt;调度器<br>4、爬虫提取数据—&gt;引擎—&gt;管道<br>5、管道进行数据的处理和保存</p>
<p>scrapy中每个模块的作用</p>
<p>引擎(engine)：负责数据和信号在不同模块间的传递<br>调度器(scheduler)：实现一个队列，存放引擎发过来的request请求对象<br>下载器(downloader)：发送引擎发过来的request请求，获取响应，并将响应交给引擎<br>爬虫(spider)：处理引擎发过来的response，提取数据，提取url，并交给引擎<br>管道(pipeline)：处理引擎传递过来的数据，比如存储<br>下载中间件(downloader middleware)：可以自定义的下载扩展，比如设置代理ip<br>爬虫中间件(spider middleware)：可以自定义request请求和进行response过滤</p>
<h2 id="scrapy的安装"><a href="#scrapy的安装" class="headerlink" title="scrapy的安装"></a>scrapy的安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">安装scrapy命令：sudo apt-get install scrapy</span><br><span class="line"></span><br><span class="line">或者(推荐)：pip install scrapy</span><br><span class="line"></span><br><span class="line">注意: 如果 pip 对应的Python2, pip3 对应的Python3, 你如果需要把scrapy安装到Python3下,那么使用的命令就是: pip3 install scrapy</span><br></pre></td></tr></table></figure>

<h3 id="创建scrapy项目"><a href="#创建scrapy项目" class="headerlink" title="创建scrapy项目"></a>创建scrapy项目</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">创建scrapy项目的命令：scrapy startproject +&lt;项目名字&gt;</span><br><span class="line">示例：scrapy startproject myspider</span><br><span class="line"></span><br><span class="line">在项目路径下执行:scrapy genspider +&lt;爬虫名字&gt; + &lt;允许爬取的域名&gt;</span><br><span class="line">示例：</span><br><span class="line"><span class="built_in">cd</span> myspider</span><br><span class="line">scrapy genspider baidu baidu.cn</span><br></pre></td></tr></table></figure>

<h2 id="编写爬虫前的准备"><a href="#编写爬虫前的准备" class="headerlink" title="编写爬虫前的准备"></a>编写爬虫前的准备</h2><h3 id="修改pipelines-py文件"><a href="#修改pipelines-py文件" class="headerlink" title="修改pipelines.py文件"></a>修改pipelines.py文件</h3><p>其中大部分的数据上传代码都在process_item方法执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line">class BaiduPipeline(object):</span><br><span class="line">    <span class="comment"># 类名可自己定义</span></span><br><span class="line">    <span class="comment"># 爬虫文件中提取数据的方法每yield一次item，就会运行一次</span></span><br><span class="line">    <span class="comment"># 该方法为固定名称函数</span></span><br><span class="line">    def process_item(self, item, spider):  </span><br><span class="line">        <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure>

<h3 id="2-在settings-py设置开启pipeline"><a href="#2-在settings-py设置开启pipeline" class="headerlink" title="2. 在settings.py设置开启pipeline"></a>2. 在settings.py设置开启pipeline</h3><p>只有爬取的数据需要上传到数据库中的时候就要用到pipline,就需要到settings里进行配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># 键(key)  完整类名: 模块.类名</span></span><br><span class="line">    <span class="comment"># 值(优先级): 是一个0-1000的整数, 越小越先执行</span></span><br><span class="line">    <span class="string">'myspider.pipelines.BaiduPipeline'</span>: 400</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="运行scrapy"><a href="#运行scrapy" class="headerlink" title="运行scrapy"></a>运行scrapy</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">命令：在项目目录下执行scrapy crawl +&lt;爬虫名字&gt;</span><br><span class="line">示例：scrapy crawl baidu</span><br></pre></td></tr></table></figure>

<h3 id="在运行时将数据导出为文件-Feed-exports"><a href="#在运行时将数据导出为文件-Feed-exports" class="headerlink" title="在运行时将数据导出为文件(Feed exports)"></a>在运行时将数据导出为文件(Feed exports)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出JSON格式，默认为Unicode编码</span></span><br><span class="line">scrapy crawl baidu -o teachers.json</span><br><span class="line"><span class="comment"># 输出JSON Lines格式，默认为Unicode编码</span></span><br><span class="line">scrapy crawl baidu -o teachers.jsonlines</span><br><span class="line"><span class="comment"># 输出CSV格式，使用逗号表达式，可用Excel打开</span></span><br><span class="line">scrapy crawl baidu -o teachers.csv</span><br><span class="line"><span class="comment"># 输出XML格式</span></span><br><span class="line">scrapy crawl baidu -o teachers.xml</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1、Scrapy的安装：pip install scrapy</span><br><span class="line">2、创建scrapy的项目: scrapy startproject myspider</span><br><span class="line">3、创建scrapy爬虫：在项目目录下执行 scrapy genspider baodu baidu.cn</span><br><span class="line">4、运行scrapy爬虫：在项目目录下执行 scrapy crawl baidu</span><br><span class="line">5、解析并获取scrapy爬虫中的数据：</span><br><span class="line">    response.xpath() 方法的返回结果是一个类似list的类型，其中包含的是selector对象，操作和列表一样，但是有一些额外的方法</span><br><span class="line">    extract() 返回一个包含有字符串的列表</span><br><span class="line">    extract_first() 返回列表中的第一个字符串，列表为空没有返回None</span><br><span class="line">6、scrapy管道的基本使用:</span><br><span class="line">    完善pipelines.py中的 process_item 函数</span><br><span class="line">    在settings.py中设置开启pipeline</span><br><span class="line">    ITEM_PIPELINES = &#123;</span><br><span class="line">        <span class="string">'myspider.pipelines.BaiduPipeline'</span>: 400</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h2 id="爬取猎聘网招聘信息"><a href="#爬取猎聘网招聘信息" class="headerlink" title="爬取猎聘网招聘信息"></a>爬取猎聘网招聘信息</h2><p>爬取猎聘网信息并上传到mongdb数据库中</p>
<p>在创建好项目后再项目的settings.py中配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = False  <span class="comment">#遵守robots . txt规则，默认是True，要改成False不然爬取不了</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;      <span class="comment"># 因为上传数据库中，所以开启pipelines</span></span><br><span class="line">   <span class="comment"># 'lieping.pipelines.LiepingPipeline': 300,</span></span><br><span class="line">    <span class="string">'lieping.pipelines.LiePinMongodb'</span>: 300,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接数据库，因为我的mongodb有权限设置，所以在下面要进行用户名密码的配置</span></span><br><span class="line">user = <span class="string">"python"</span> </span><br><span class="line">password = <span class="string">"python"</span>  </span><br><span class="line">host = <span class="string">"106.12.xxx.xxx"</span> （自己服务器的IP）</span><br></pre></td></tr></table></figure>

<p>在settings配置完后，就准备写入爬虫主程序的代码编写</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import scrapy,re</span><br><span class="line">from scrapy import Request</span><br><span class="line"></span><br><span class="line">class LiepinSpider(scrapy.Spider):</span><br><span class="line">    name = <span class="string">'liepin'</span></span><br><span class="line">    allowed_domains = [<span class="string">'liepin.com'</span>]</span><br><span class="line">    <span class="comment"># start_urls = ['http://liepin.com/']</span></span><br><span class="line"></span><br><span class="line">    def start_requests(self):  <span class="comment">#重写url指定的方法</span></span><br><span class="line">        cur_page = -2</span><br><span class="line">        page = -1</span><br><span class="line">        <span class="keyword">while</span> True:</span><br><span class="line">            cur_page = cur_page + 1</span><br><span class="line">            page = page + 1</span><br><span class="line">            urls = r<span class="string">'https://www.liepin.com/zhaopin/?isAnalysis=&amp;dqs=&amp;pubTime=&amp;salary=&amp;subIndustry=&amp;industryType=&amp;compscale=&amp;key=python%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91&amp;init=-1&amp;searchType=1&amp;headckid=f55990a321cbc78b&amp;compkind=&amp;fromSearchBtn=2&amp;sortFlag=15&amp;ckid=f55990a321cbc78b&amp;degradeFlag=0&amp;jobKind=&amp;industries=&amp;clean_condition=&amp;siTag=d95cAhX-dp0D2puIzlfHZQ~fA9rXquZc5IkJpXC-Ycixw&amp;d_sfrom=search_fp_bar&amp;d_ckId=8c8c9184e4f015f91103131fb15317d8&amp;d_curPage=&#123;&#125;&amp;d_pageSize=40&amp;d_headId=8c8c9184e4f015f91103131fb15317d8&amp;curPage=&#123;&#125;'</span>.format(cur_page,page)</span><br><span class="line">            yield Request(urls,callback=self.parse)</span><br><span class="line">            <span class="keyword">if</span> page == 15:</span><br><span class="line">                <span class="built_in">break</span></span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        ul = response.xpath(r<span class="string">"//ul[@class='sojob-list']/li"</span>)</span><br><span class="line">        info = &#123;<span class="string">"con"</span>:[]&#125;</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> ul:</span><br><span class="line">            title = li.xpath(r<span class="string">".//h3/@title"</span>).get()</span><br><span class="line">            new_title = title.replace(<span class="string">'招聘'</span>,<span class="string">''</span>)</span><br><span class="line">            money = li.xpath(r<span class="string">".//span[@class='text-warning']/text()"</span>).get()</span><br><span class="line">            city = li.xpath(r<span class="string">".//p[@class='condition clearfix']//a/text()"</span>).get()</span><br><span class="line">            education =li.xpath(r<span class="string">".//span[@class='edu']/text()"</span>).get()</span><br><span class="line">            worktime = li.xpath(r<span class="string">".//span[3]/text()"</span>).get()</span><br><span class="line">            user = info[<span class="string">'con'</span>].append(&#123;<span class="string">"工作岗位"</span>:new_title,<span class="string">"薪酬"</span>:money,<span class="string">"工作地址"</span>:city,<span class="string">"学历"</span>:education,<span class="string">"工作时间"</span>:worktime&#125;)</span><br><span class="line">        <span class="built_in">return</span> info  <span class="comment">#因为上传数据库中，要以字典的形式传到piplines.py文件中</span></span><br></pre></td></tr></table></figure>

<p>爬虫代码编写好后就开始对数据进行上传，在piplines.py文件的编写</p>
<pre><code class="bash"><span class="comment"># -*- coding: utf-8 -*-</span>

<span class="comment"># Define your item pipelines here</span>
<span class="comment">#</span>
<span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>

from . import settings
from pymongo import MongoClient
from urllib.parse import quote_plus

class LiepingPipeline(object):
    def process_item(self, item, spider):
        <span class="built_in">return</span> item

class LiePinMongodb():
<span class="comment">#下面的函数名是指定的不能更改</span>
    def open_spider(self,spider):  <span class="comment">#连接MongoDB数据库的配置</span>
        url = <span class="string">"mongodb://%s:%s@%s"</span> % (
        quote_plus(settings.user), quote_plus(settings.password), quote_plus(settings.host))
        self.client = MongoClient(url)
        self.coll = self.client[<span class="string">"liepin"</span>][<span class="string">"user"</span>]
        <span class="built_in">print</span>(<span class="string">'i am center'</span>)

    def process_item(self, item, spider): <span class="comment">#爬取下来的数据进行上传</span>
        self.coll.insert(item[<span class="string">'con'</span>])
        <span class="built_in">return</span> item[<span class="string">'con'</span>]

    def colse_spider(self,spider):  <span class="comment">#关闭数据库</span>
        self.client.close()
``` bash
</code></pre>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/27/VIP视频破译/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/27/VIP视频破译/" class="post-title-link" itemprop="url">VIP视频破译</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-27 17:05:00 / Geändert am: 17:17:20" itemprop="dateCreated datePublished" datetime="2019-07-27T17:05:00+08:00">2019-07-27</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="VIP视频的API调用"><a href="#VIP视频的API调用" class="headerlink" title="VIP视频的API调用"></a>VIP视频的API调用</h2><p>本次技术主要是用到pyqt5做一个UI界面（这个是主要的技术）<br>通过用户输入的网址到后台对API接口的拼接实现VIP视频的破译，主要用到的技术不难</p>
<p>源码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">import webbrowser,re,sys</span><br><span class="line"></span><br><span class="line"><span class="comment">#vip视频破解接口</span></span><br><span class="line"><span class="comment"># url = 'https://www.administratorw.com/video.php?url='</span></span><br><span class="line"><span class="comment">#打开网页的命令</span></span><br><span class="line"><span class="comment"># webbrowser.open(url, new=0, autoraise=True)</span></span><br><span class="line"></span><br><span class="line">from PyQt5.QtWidgets import QApplication,QWidget,QToolTip, QPushButton,QLabel,QLineEdit,QGridLayout,QMessageBox,QRadioButton,QComboBox</span><br><span class="line">from PyQt5.QtGui import QFont</span><br><span class="line"></span><br><span class="line">WIGTH_SIZE = 500</span><br><span class="line">HEIGHT_SIZE = 100</span><br><span class="line">class UI(QWidget,QApplication):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.initUI()</span><br><span class="line"></span><br><span class="line">    def initUI(self):</span><br><span class="line">        label1 = QLabel(self)</span><br><span class="line">        label1.setText(<span class="string">'vip视频url：'</span>)</span><br><span class="line">        label1.move(5,50)</span><br><span class="line"></span><br><span class="line">        self.textbox = QLineEdit(self)</span><br><span class="line">        self.textbox.move(90, 50)</span><br><span class="line">        self.textbox.resize(300, 20)</span><br><span class="line"></span><br><span class="line">        btn1 = QPushButton(<span class="string">'观看'</span>, self)</span><br><span class="line">        btn1.setToolTip(<span class="string">'这是一个提交按钮，在后台拼接url'</span>)</span><br><span class="line">        btn1.move(400, 50)</span><br><span class="line">        btn1.clicked.connect(self.buttonClicked)</span><br><span class="line"></span><br><span class="line">        items = [<span class="string">'链接1'</span>,<span class="string">'链接2'</span>]</span><br><span class="line">        self.combo = QComboBox(self)</span><br><span class="line">        self.combo.addItems(items)</span><br><span class="line">        self.combo.move(10, 10)</span><br><span class="line">        self.combo.activated[str].connect(self.Link)</span><br><span class="line"></span><br><span class="line">        self.setGeometry(300, 300, WIGTH_SIZE, HEIGHT_SIZE)</span><br><span class="line">        self.setWindowTitle(<span class="string">'vip视频'</span>)</span><br><span class="line">        self.show()</span><br><span class="line"></span><br><span class="line">    def Link(self):</span><br><span class="line">        link = self.combo.currentText()</span><br><span class="line">        <span class="keyword">if</span> link == <span class="string">"链接1"</span>:</span><br><span class="line">            url = <span class="string">'https://www.administratorw.com/video.php?url='</span></span><br><span class="line">            <span class="built_in">print</span>(url)</span><br><span class="line">            <span class="built_in">return</span> url</span><br><span class="line">        <span class="keyword">elif</span> link == <span class="string">"链接2"</span>:</span><br><span class="line">            url = <span class="string">'https://jx.618g.com/?url='</span></span><br><span class="line">            <span class="built_in">print</span>(url)</span><br><span class="line">            <span class="built_in">return</span> url</span><br><span class="line"></span><br><span class="line">    def buttonClicked(self):</span><br><span class="line">        text_con = self.textbox.text()</span><br><span class="line">        <span class="keyword">if</span> text_con is <span class="string">''</span>:</span><br><span class="line">            QMessageBox.warning(self, <span class="string">"警告"</span>, <span class="string">"输入的url不能为空！"</span>, QMessageBox.Cancel)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#接口：</span></span><br><span class="line">            <span class="keyword">if</span> re.match(r<span class="string">'https://\w.*'</span>,text_con) or re.match(r<span class="string">"http://\w.*"</span>,text_con):</span><br><span class="line">                <span class="comment">#调用接口函数</span></span><br><span class="line">                links = self.Link()</span><br><span class="line">                url = links+text_con</span><br><span class="line">                webbrowser.open(url,new=0, autoraise=True)</span><br><span class="line">                self.textbox.clear()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                QMessageBox.warning(self, <span class="string">"警告"</span>, <span class="string">"您输入的url有误，请重新输入！"</span>, QMessageBox.Cancel)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    ui = UI()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/26/mongodb数据库的使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/26/mongodb数据库的使用/" class="post-title-link" itemprop="url">mongodb数据库的使用</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-26 15:54:47" itemprop="dateCreated datePublished" datetime="2019-07-26T15:54:47+08:00">2019-07-26</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-07-27 17:17:02" itemprop="dateModified" datetime="2019-07-27T17:17:02+08:00">2019-07-27</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="mongodb安装配置"><a href="#mongodb安装配置" class="headerlink" title="mongodb安装配置"></a>mongodb安装配置</h2><p>在ubuntu系统中使用以下命令安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y mongodb-org</span><br></pre></td></tr></table></figure>

<p>服务器的启动与配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">启动：sudo service mongodb start</span><br><span class="line">停止：sudo service mongodb stop</span><br><span class="line">重启：sudo service mongodb restart</span><br><span class="line">配置文件的位置：/etc/mongodb.conf，</span><br><span class="line">上面四个命令只有使用apt-get安装才有</span><br><span class="line">手动安装</span><br><span class="line"></span><br><span class="line">下载解压</span><br><span class="line">tar -zxvf mongodb-linux-x86_64-ubuntu1604-3.6.3.tgz</span><br><span class="line">移动到usr/<span class="built_in">local</span>目录下</span><br><span class="line">sudo mv mongodb-linux-x86_64-ubuntu1604-3.6.3 /usr/<span class="built_in">local</span>/mongodb</span><br><span class="line">把可以执行文件路径添加到<span class="variable">$PATH</span>变量下</span><br><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/mongodb/bin:<span class="variable">$PATH</span></span><br><span class="line">说明: 在 命令行执行只对当前窗口有效, 添加到.bashrc中每次启动都有效</span><br></pre></td></tr></table></figure>

<h2 id="mongodb基本命令"><a href="#mongodb基本命令" class="headerlink" title="mongodb基本命令"></a>mongodb基本命令</h2><p>操作数据库命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">查看当前的数据库：db</span><br><span class="line">查看所有的数据库：show dbs /show databases</span><br><span class="line">切换数据库：use db_name</span><br><span class="line">切换到没有的数据库, 添加数据会自动创建</span><br><span class="line">删除当前的数据库：db.dropDatabase()</span><br></pre></td></tr></table></figure>

<p>操作集合命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">不手动创建集合：</span><br><span class="line">向不存在的集合中第⼀次加⼊数据时， 集合会被创建出来</span><br><span class="line">手动创建结合(了解)：</span><br><span class="line"></span><br><span class="line">db.createCollection(name,options)</span><br><span class="line">db.createCollection(<span class="string">"stu"</span>)</span><br><span class="line">db.createCollection(<span class="string">"sub"</span>, &#123; capped : <span class="literal">true</span>, size : 10 &#125; )</span><br><span class="line">参数capped： 默认值为<span class="literal">false</span>表示不设置上限,值为<span class="literal">true</span>表示设置上限</span><br><span class="line">参数size： 当capped值为<span class="literal">true</span>时， 需要指定此参数， 表示上限,单位为字节</span><br><span class="line">当档达到上限时， 会将之前的数据覆盖， 最早添加的数据移出, 其余上移, 最后添加在最后一条</span><br><span class="line">查看集合：show collections</span><br><span class="line">删除集合：db.集合名称.drop()</span><br></pre></td></tr></table></figure>

<h2 id="mongodb中的数据类型"><a href="#mongodb中的数据类型" class="headerlink" title="mongodb中的数据类型"></a>mongodb中的数据类型</h2><p>String： 字符串， 最常使用 必须是有效的UTF-8<br>Boolean： 存储多个布尔值， true或false<br>Integer： 整数可以是32位或64位， 这取决于服务器<br>Double： 存储浮点值<br>Null： 存储Null值<br>Timestamp： 时间戳， 表示从1970-1-1到现在的总秒数<br>Date： 存储当前日期或时间的UNIX时间格式</p>
<h2 id="mongodb的增删改查"><a href="#mongodb的增删改查" class="headerlink" title="mongodb的增删改查"></a>mongodb的增删改查</h2><p>插入数据</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">db.集合名称.insert(document)</span><br><span class="line">db.stu.insert(&#123;name:<span class="string">'gj'</span>,gender:1&#125;)</span><br><span class="line">db.stu.insert(&#123;_id:<span class="string">"20170101"</span>,name:<span class="string">'gj'</span>,gender:1&#125;)</span><br><span class="line">插入数据时，如果不指定_id参数， MongoDB会为自动分配ID</span><br><span class="line">插入单条指定为字典, 插入多条指定为列表</span><br></pre></td></tr></table></figure>

<p>保存</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">db.集合名称.save(document)</span><br><span class="line">如果_id已经存在则修改， 如果⽂档的_id不存在则添加</span><br><span class="line">区别于: insert如果存在直接报错</span><br></pre></td></tr></table></figure>

<p>简单查询</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.集合名称.find()</span><br></pre></td></tr></table></figure>

<p>更新</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">语法: db.集合名称.update(&lt;query&gt; ,&lt;update&gt;,&#123;multi: &lt;boolean&gt;&#125;)</span><br><span class="line">参数query:查询条件</span><br><span class="line">参数update:更新操作符</span><br><span class="line">参数multi:可选， 默认是<span class="literal">false</span>，表示只更新找到的第⼀条记录， 值为<span class="literal">true</span>表示把满⾜条件的⽂档全部更新</span><br><span class="line">举例:</span><br><span class="line">db.stu.update(&#123;name:<span class="string">'hr'</span>&#125;,&#123;name:<span class="string">'mnc'</span>&#125;) 更新一条,没有更新的字段会丢弃.</span><br><span class="line">db.stu.update(&#123;name:<span class="string">'hr'</span>&#125;,&#123;<span class="variable">$set</span>:&#123;name:<span class="string">'hys'</span>&#125;&#125;) 更新一条</span><br><span class="line">db.stu.update(&#123;&#125;,&#123;<span class="variable">$set</span>:&#123;gender:0&#125;&#125;,&#123;multi:<span class="literal">true</span>&#125;) 更新全部</span><br><span class="line">注意：<span class="string">"multi update only works with $ operators"</span> 更新全部,必须使用<span class="variable">$set</span></span><br></pre></td></tr></table></figure>

<p>删除</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法: db.集合名称.remove(&lt;query&gt;,&#123;justOne: &lt;boolean&gt;&#125;)</span><br><span class="line">参数query:可选，删除数据的条件</span><br><span class="line">参数justOne:可选， 如果设为<span class="literal">true</span>或1， 则只删除⼀条， 默认<span class="literal">false</span>， 表示删除多条</span><br></pre></td></tr></table></figure>


          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/25/Selenium模拟请求爬取数据与防爬/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/25/Selenium模拟请求爬取数据与防爬/" class="post-title-link" itemprop="url">Selenium模拟请求爬取数据与反扒机制</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-25 13:41:14" itemprop="dateCreated datePublished" datetime="2019-07-25T13:41:14+08:00">2019-07-25</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-07-27 17:17:06" itemprop="dateModified" datetime="2019-07-27T17:17:06+08:00">2019-07-27</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Selenium简介"><a href="#Selenium简介" class="headerlink" title="Selenium简介"></a>Selenium简介</h2><p>Selenium是一种自动化测试工具，它支持各种浏览器，包括 Chrome，Safari，Firefox 等主流界面式浏览器，如果你在这些浏览器里面安装一个 Selenium 的插件，那么便可以方便地实现Web界面的测试。换句话说叫 Selenium 支持这些浏览器驱动。<br>我们可以用Selenium来模拟正常用户浏览服务器的请求，实现简要的数据爬取。</p>
<p>Selenium 安装</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure>

<p>ChromeDriver下载安装:<br>注意下载的版本号要支持你的浏览器<br>淘宝镜像<br>ChromeDriver淘宝镜像：<a href="http://npm.taobao.org/" target="_blank" rel="noopener">http://npm.taobao.org/</a><br>注意查看chromedriver支持的版本 ：<a href="https://npm.taobao.org/mirrors/chromedriver/2.38/notes.txt" target="_blank" rel="noopener">https://npm.taobao.org/mirrors/chromedriver/2.38/notes.txt</a><br>Linux 或 Mac 解压后直接拷贝到usr/local/bin 或 usr/bin 下即可; 也可以制作软连接放到上面的两个路径下<br>在Linux或Mac中如果报关于Permission的错误, 是因为chromedriver这个文件没有执行权限, 就修改chromedriver文件的权限为 777<br>chmod 777 chromedriver</p>
<h2 id="Selenium入门"><a href="#Selenium入门" class="headerlink" title="Selenium入门"></a>Selenium入门</h2><p>加载网页：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">driver = webdriver.Chrome()  如果是Windows()中传入driver的路径: “c:…/pantomjs.exe”</span><br><span class="line">driver.get(<span class="string">"http://www.baidu.com/"</span>) <span class="comment"># 加载页面 百度首页</span></span><br><span class="line">driver.save_screenshot(<span class="string">"baidu.png"</span>) <span class="comment"># 保存当前界面</span></span><br></pre></td></tr></table></figure>

<p>定位和操作：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.find_element_by_id(“kw”).send_keys(“python”)   <span class="comment"># 找到id为kw的输入框, 填写: python</span></span><br><span class="line">driver.find_element_by_id(<span class="string">"su"</span>).click()  <span class="comment"># 找到id为su的, 进行单击</span></span><br></pre></td></tr></table></figure>

<p>查看请求信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">driver.page_source   <span class="comment"># 获取页面的源码</span></span><br><span class="line">driver.get_cookies() <span class="comment"># 获取cookie信息</span></span><br><span class="line">driver.current_url   <span class="comment"># 获取当前的URL</span></span><br></pre></td></tr></table></figure>

<p>这个比较少用到，主要看需求吧</p>
<p>退出</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.close() <span class="comment">#退出当前页面</span></span><br><span class="line">driver.quit() <span class="comment">#退出浏览器</span></span><br></pre></td></tr></table></figure>

<h2 id="Selenium中操作cookie的方法"><a href="#Selenium中操作cookie的方法" class="headerlink" title="Selenium中操作cookie的方法"></a>Selenium中操作cookie的方法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;cookie[‘name’]: cookie[‘value’] <span class="keyword">for</span> cookie <span class="keyword">in</span> driver.get_cookies()&#125;</span><br><span class="line">driver.delete_cookie(<span class="string">"CookieName"</span>)</span><br><span class="line">driver.delete_all_cookies()</span><br></pre></td></tr></table></figure>

<h2 id="selenium定位页面元素"><a href="#selenium定位页面元素" class="headerlink" title="selenium定位页面元素"></a>selenium定位页面元素</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">find_element_by_id (返回一个,如果没有就报错了)</span><br><span class="line">find_elements_by_xpath （返回一个列表,如果没有就返回一个空列表）</span><br><span class="line">find_elements_by_link_text (根据文本内容返回元素列表, 如果没有返回空列表)</span><br><span class="line">find_elements_by_partial_link_text (根据文件部分内容返回元素列表, 如果没有返回空列表)</span><br><span class="line">find_elements_by_tag_name(根据标签名[节点名]返回元素元素列表, 如果没有返回空列表)</span><br><span class="line">find_elements_by_class_name(根据class属性对应值范围元素列表, 如果没有返回空列表)</span><br><span class="line">find_elements_by_css_selector(根据css选择器返回元素列表, 如果没有返回空列表)</span><br></pre></td></tr></table></figure>

<p>具体用法自行百度搜索</p>
<p>注意点:</p>
<p>find_element 和find_elements的区别：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find_element: 返回找到第一个元素,如果没有报错</span><br><span class="line">find_elements: 返回找到的所有元素列表, 如果没有找到返回空列表</span><br></pre></td></tr></table></figure>

<p>by_link_text和by_partial_link_text的区别：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">by_link_text: 全部文本都一样</span><br><span class="line">by_partial_link_text: 包含某个文本</span><br></pre></td></tr></table></figure>

<p>by_link_text这个平常也很少用<br>by_xpath只能获取元素, 要获取属性和文本需要使用get_attribute(属性名) 和.text</p>
<h2 id="Selenium处理反扒的措施"><a href="#Selenium处理反扒的措施" class="headerlink" title="Selenium处理反扒的措施"></a>Selenium处理反扒的措施</h2><p>解决办法就是——用webdirver接管我们自己打开的浏览器，然后再进行登录操作。</p>
<p>文章参考：<br>Selenium的反扒环境配置：<a href="https://blog.csdn.net/qq_42206477/article/details/86477446?utm_source=app" target="_blank" rel="noopener">https://blog.csdn.net/qq_42206477/article/details/86477446?utm_source=app</a><br>具体的接管方法：<a href="https://www.cnblogs.com/HJkoma/p/9936434.html" target="_blank" rel="noopener">https://www.cnblogs.com/HJkoma/p/9936434.html</a></p>
<h2 id="用Selenium爬取拉钩python的所有职位信息"><a href="#用Selenium爬取拉钩python的所有职位信息" class="headerlink" title="用Selenium爬取拉钩python的所有职位信息"></a>用Selenium爬取拉钩python的所有职位信息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver import ActionChains</span><br><span class="line">import time,json,csv,re</span><br><span class="line"></span><br><span class="line">class LaGou():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.drive = webdriver.Chrome()</span><br><span class="line">        self.ul = self.drive.get(r<span class="string">'https://www.lagou.com/jobs/list_java?city=%E5%B9%BF%E5%B7%9E&amp;cl=false&amp;fromSearch=true&amp;labelWords=&amp;suginput='</span>)</span><br><span class="line"></span><br><span class="line">    def gundong(self):  <span class="comment">#自动滚动页面</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(0, 10500, 500):</span><br><span class="line">            jsCode = <span class="string">"document.documentElement.scrollTop=%s"</span> % i</span><br><span class="line">            self.drive.execute_script(jsCode)</span><br><span class="line">            time.sleep(0.3)</span><br><span class="line"></span><br><span class="line">    def get_info(self):  <span class="comment">#获取页面详细信息</span></span><br><span class="line">        ul = self.drive.find_elements_by_xpath(r<span class="string">'//*[@id="s_position_list"]/ul//li'</span>)</span><br><span class="line">        user_info = []</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> ul:</span><br><span class="line">            work = li.find_element_by_xpath(r<span class="string">".//h3"</span>).text</span><br><span class="line">            money = li.find_element_by_xpath(r<span class="string">".//div[@class='li_b_l']/span[@class='money']"</span>).text</span><br><span class="line">            xueli1 = li.find_element_by_xpath(r<span class="string">".//div[@class='p_bot']/div"</span>).text</span><br><span class="line">            xueli = re.search(r<span class="string">'/ (\w.*)'</span>, xueli1).group(1)</span><br><span class="line">            company_name = li.find_element_by_xpath(r<span class="string">".//div[@class='company_name']/a"</span>).text</span><br><span class="line">            user_info.append([work,money,xueli,company_name])</span><br><span class="line">        <span class="built_in">print</span>(user_info)</span><br><span class="line">        <span class="built_in">return</span> user_info</span><br><span class="line"></span><br><span class="line">    def mouser_clink(self):  <span class="comment">#鼠标点击事件</span></span><br><span class="line">        ac =self.drive.find_element_by_xpath(r<span class="string">"//div[@class='pager_container']/span[@class='pager_next ']"</span>)</span><br><span class="line">        ActionChains(self.drive).move_to_element(ac).click(ac).perform()</span><br><span class="line">    </span><br><span class="line">    def save(self,info):    <span class="comment">#保存数据，保存成Excel表中</span></span><br><span class="line">        with open(<span class="string">'java.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) as f:</span><br><span class="line">            writer = csv.writer(f)</span><br><span class="line">            writer.writerow([<span class="string">"工种"</span>,<span class="string">"薪酬"</span>,<span class="string">"学历"</span>,<span class="string">"公司名"</span>])</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> info:</span><br><span class="line">                writer.writerows(info)<span class="comment"># 还可以写入多行</span></span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(30):</span><br><span class="line">            self.gundong()</span><br><span class="line">            info = self.get_info()</span><br><span class="line">            self.save(info)</span><br><span class="line">            self.mouser_clink()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    lagou = LaGou()</span><br><span class="line">    lagou.run()</span><br></pre></td></tr></table></figure>

<h2 id="用Selenium爬取拼多多（添加对selenium的反扒）"><a href="#用Selenium爬取拼多多（添加对selenium的反扒）" class="headerlink" title="用Selenium爬取拼多多（添加对selenium的反扒）"></a>用Selenium爬取拼多多（添加对selenium的反扒）</h2><p>项目分析：<br>拼多多这个网站的反扒机制比较强烈，个人研究了一天了终于爬取部分数据。拼多多的网页版界面已经不再维护了，所以我换了个url<br>访问的url：<a href="http://mobile.yangkeduo.com/" target="_blank" rel="noopener">http://mobile.yangkeduo.com/</a></p>
<p>前提是要配置好对selenium的接管操作，每次运行时都要在cmd窗口里运行：chrome.exe –remote-debugging-port=9222 –user-data-dir=”C:\selenum\AutomationProfile”</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver import ChromeOptions</span><br><span class="line">from selenium.webdriver.chrome.options import Options</span><br><span class="line">import time,requests,csv</span><br><span class="line"></span><br><span class="line">class Pinduoduo():</span><br><span class="line">    def __init__(self,con):</span><br><span class="line">        self.chrome_options = Options()</span><br><span class="line">        self.chrome_options.add_experimental_option(<span class="string">"debuggerAddress"</span>, <span class="string">"127.0.0.1:9222"</span>)</span><br><span class="line">        self.chrome_driver = r<span class="string">"C:\Users\Administrator.SKY-20190217ZDF\AppData\Local\Google\Chrome\Application\chrome.exe"</span></span><br><span class="line">        self.driver = webdriver.Chrome(options=self.chrome_options)</span><br><span class="line">        self.ul = self.driver.get(r<span class="string">"http://mobile.yangkeduo.com/search_result.html?search_key=&#123;&#125;"</span>.format(con))</span><br><span class="line"></span><br><span class="line">    def get_info(self):</span><br><span class="line">        self.urls = self.driver.find_elements_by_xpath(r<span class="string">"//div[@class='_2EdaAb7m']/div"</span>)</span><br><span class="line">        user_info = []</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> self.urls:</span><br><span class="line">            try:</span><br><span class="line">                images = li.find_element_by_xpath(r<span class="string">".//div[@class='bqyzKuVp _2nXx5SjD']/img"</span>).get_attribute(<span class="string">"src"</span>)</span><br><span class="line">                title = li.find_element_by_xpath(r<span class="string">".//div[@class='troiqcp4 OSSkI8pu']"</span>).text</span><br><span class="line">                money = li.find_element_by_xpath(r<span class="string">".//div[@class='W2aG482G']"</span>).text</span><br><span class="line">                buysum = li.find_element_by_xpath(r<span class="string">".//span[@class='_2zosSFdU']"</span>).text</span><br><span class="line">                user_info.append([images,title,money,buysum])</span><br><span class="line">            except Exception:</span><br><span class="line">                pass</span><br><span class="line">        <span class="built_in">print</span>(user_info)</span><br><span class="line">        <span class="built_in">return</span> user_info</span><br><span class="line"></span><br><span class="line">    def save(self,info):</span><br><span class="line">        with open(<span class="string">'pinduoduo.csv'</span>, <span class="string">'a'</span>, newline=<span class="string">''</span>,encoding=<span class="string">"utf-8"</span>) as f:</span><br><span class="line">            writer = csv.writer(f)</span><br><span class="line">            writer.writerows(info)<span class="comment"># 还可以写入多行</span></span><br><span class="line"></span><br><span class="line">    def gun(self):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(0, 500000, 1000):</span><br><span class="line">            <span class="built_in">print</span>(i)</span><br><span class="line">            jsCode = <span class="string">"document.documentElement.scrollTop=%s"</span> % i</span><br><span class="line">            self.driver.execute_script(jsCode)</span><br><span class="line">            time.sleep(1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pin = Pinduoduo(<span class="string">"小白鞋"</span>)</span><br><span class="line">    pin.gun()</span><br><span class="line">    info = pin.get_info()</span><br><span class="line">    pin.save(info)</span><br></pre></td></tr></table></figure>

<p>如果显示了登录界面就是你访问的次数多了。。。。。。。</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Nächste Seite"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
  <p class="site-author-name" itemprop="name">ssc</p>
  <div class="site-description motion-element" itemprop="description">关于ssc学习python的艰辛之旅</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">Artikel</span>
        </a>
      </div>
    

    

    
  </nav>













          
          
        </div>
      </div>

      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
        <title>Live2D！把可爱的看板娘扑捉到你的博客去吧！</title>
          <link rel="stylesheet" href="/live2d/css/live2d.css">
      <div id="landlord">
          <div class="message" style="opacity:0"></div>
          <canvas id="live2d" width="280" height="250" class="live2d"></canvas>
          <div class="hide-button">隐藏</div>
      </div>
      <script type="text/javascript" src="https://cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
      <script type="text/javascript">
          var message_Path = '/live2d/'
          var home_Path = 'https://www.baidu.com/'
      </script>
      <script type="text/javascript" src="/live2d/js/live2d.js"></script>
      <script type="text/javascript" src="/live2d/js/message.js"></script>
      <script type="text/javascript">
          loadlive2d("live2d", "/live2d/model/tia/model.json");
      </script>
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ssc</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Design – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    

  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


















  
  









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>



  

  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  


  






























<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>








  

</body>
</html>

<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="china">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    fastclick: false,
    lazyload: false,
    pangu: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Kopieren',
      copy_success: 'Kopiert',
      copy_failure: 'Kopieren fehlgeschlagen'
    }
  };
</script>

  <meta name="description" content="关于ssc学习python的艰辛之旅">
<meta name="keywords" content="ssc_python">
<meta property="og:type" content="website">
<meta property="og:title" content="Welcome to ssc bolg !">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Welcome to ssc bolg !">
<meta property="og:description" content="关于ssc学习python的艰辛之旅">
<meta property="og:locale" content="china">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Welcome to ssc bolg !">
<meta name="twitter:description" content="关于ssc学习python的艰辛之旅">





  
  
  <link rel="canonical" href="http://yoursite.com/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>Welcome to ssc bolg !</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="china">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Welcome to ssc bolg !</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">ssc bolg</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Navigationsleiste an/ausschalten">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archiv</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/28/scrapy框架/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/28/scrapy框架/" class="post-title-link" itemprop="url">scrapy框架</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-28 12:53:18" itemprop="dateCreated datePublished" datetime="2019-07-28T12:53:18+08:00">2019-07-28</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-07-29 11:12:40" itemprop="dateModified" datetime="2019-07-29T11:12:40+08:00">2019-07-29</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="scrapy框架工作结构"><a href="#scrapy框架工作结构" class="headerlink" title="scrapy框架工作结构"></a>scrapy框架工作结构</h2><p>scrapy框架运行流程</p>
<p>1、调度器把requests–&gt;引擎–&gt;下载中间件—&gt;下载器<br>2、下载器发送请求，获取响应—-&gt;下载中间件—-&gt;引擎—&gt;爬虫中间件—&gt;爬虫<br>3、爬虫提取url地址，组装成request对象—-&gt;爬虫中间件—&gt;引擎—&gt;调度器<br>4、爬虫提取数据—&gt;引擎—&gt;管道<br>5、管道进行数据的处理和保存</p>
<p>scrapy中每个模块的作用</p>
<p>引擎(engine)：负责数据和信号在不同模块间的传递<br>调度器(scheduler)：实现一个队列，存放引擎发过来的request请求对象<br>下载器(downloader)：发送引擎发过来的request请求，获取响应，并将响应交给引擎<br>爬虫(spider)：处理引擎发过来的response，提取数据，提取url，并交给引擎<br>管道(pipeline)：处理引擎传递过来的数据，比如存储<br>下载中间件(downloader middleware)：可以自定义的下载扩展，比如设置代理ip<br>爬虫中间件(spider middleware)：可以自定义request请求和进行response过滤</p>
<h2 id="scrapy的安装"><a href="#scrapy的安装" class="headerlink" title="scrapy的安装"></a>scrapy的安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">安装scrapy命令：sudo apt-get install scrapy</span><br><span class="line"></span><br><span class="line">或者(推荐)：pip install scrapy</span><br><span class="line"></span><br><span class="line">注意: 如果 pip 对应的Python2, pip3 对应的Python3, 你如果需要把scrapy安装到Python3下,那么使用的命令就是: pip3 install scrapy</span><br></pre></td></tr></table></figure>

<h3 id="创建scrapy项目"><a href="#创建scrapy项目" class="headerlink" title="创建scrapy项目"></a>创建scrapy项目</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">创建scrapy项目的命令：scrapy startproject +&lt;项目名字&gt;</span><br><span class="line">示例：scrapy startproject myspider</span><br><span class="line"></span><br><span class="line">在项目路径下执行:scrapy genspider +&lt;爬虫名字&gt; + &lt;允许爬取的域名&gt;</span><br><span class="line">示例：</span><br><span class="line"><span class="built_in">cd</span> myspider</span><br><span class="line">scrapy genspider baidu baidu.cn</span><br></pre></td></tr></table></figure>

<h2 id="编写爬虫前的准备"><a href="#编写爬虫前的准备" class="headerlink" title="编写爬虫前的准备"></a>编写爬虫前的准备</h2><h3 id="修改pipelines-py文件"><a href="#修改pipelines-py文件" class="headerlink" title="修改pipelines.py文件"></a>修改pipelines.py文件</h3><p>其中大部分的数据上传代码都在process_item方法执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line">class BaiduPipeline(object):</span><br><span class="line">    <span class="comment"># 类名可自己定义</span></span><br><span class="line">    <span class="comment"># 爬虫文件中提取数据的方法每yield一次item，就会运行一次</span></span><br><span class="line">    <span class="comment"># 该方法为固定名称函数</span></span><br><span class="line">    def process_item(self, item, spider):  </span><br><span class="line">        <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure>

<h3 id="2-在settings-py设置开启pipeline"><a href="#2-在settings-py设置开启pipeline" class="headerlink" title="2. 在settings.py设置开启pipeline"></a>2. 在settings.py设置开启pipeline</h3><p>只有爬取的数据需要上传到数据库中的时候就要用到pipline,就需要到settings里进行配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># 键(key)  完整类名: 模块.类名</span></span><br><span class="line">    <span class="comment"># 值(优先级): 是一个0-1000的整数, 越小越先执行</span></span><br><span class="line">    <span class="string">'myspider.pipelines.BaiduPipeline'</span>: 400</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="运行scrapy"><a href="#运行scrapy" class="headerlink" title="运行scrapy"></a>运行scrapy</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">命令：在项目目录下执行scrapy crawl +&lt;爬虫名字&gt;</span><br><span class="line">示例：scrapy crawl baidu</span><br></pre></td></tr></table></figure>

<h3 id="在运行时将数据导出为文件-Feed-exports"><a href="#在运行时将数据导出为文件-Feed-exports" class="headerlink" title="在运行时将数据导出为文件(Feed exports)"></a>在运行时将数据导出为文件(Feed exports)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出JSON格式，默认为Unicode编码</span></span><br><span class="line">scrapy crawl baidu -o teachers.json</span><br><span class="line"><span class="comment"># 输出JSON Lines格式，默认为Unicode编码</span></span><br><span class="line">scrapy crawl baidu -o teachers.jsonlines</span><br><span class="line"><span class="comment"># 输出CSV格式，使用逗号表达式，可用Excel打开</span></span><br><span class="line">scrapy crawl baidu -o teachers.csv</span><br><span class="line"><span class="comment"># 输出XML格式</span></span><br><span class="line">scrapy crawl baidu -o teachers.xml</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1、Scrapy的安装：pip install scrapy</span><br><span class="line">2、创建scrapy的项目: scrapy startproject myspider</span><br><span class="line">3、创建scrapy爬虫：在项目目录下执行 scrapy genspider baodu baidu.cn</span><br><span class="line">4、运行scrapy爬虫：在项目目录下执行 scrapy crawl baidu</span><br><span class="line">5、解析并获取scrapy爬虫中的数据：</span><br><span class="line">    response.xpath() 方法的返回结果是一个类似list的类型，其中包含的是selector对象，操作和列表一样，但是有一些额外的方法</span><br><span class="line">    extract() 返回一个包含有字符串的列表</span><br><span class="line">    extract_first() 返回列表中的第一个字符串，列表为空没有返回None</span><br><span class="line">6、scrapy管道的基本使用:</span><br><span class="line">    完善pipelines.py中的 process_item 函数</span><br><span class="line">    在settings.py中设置开启pipeline</span><br><span class="line">    ITEM_PIPELINES = &#123;</span><br><span class="line">        <span class="string">'myspider.pipelines.BaiduPipeline'</span>: 400</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h2 id="爬取猎聘网招聘信息"><a href="#爬取猎聘网招聘信息" class="headerlink" title="爬取猎聘网招聘信息"></a>爬取猎聘网招聘信息</h2><p>爬取猎聘网信息并上传到mongdb数据库中</p>
<p>在创建好项目后再项目的settings.py中配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = False  <span class="comment">#遵守robots . txt规则，默认是True，要改成False不然爬取不了</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;      <span class="comment"># 因为上传数据库中，所以开启pipelines</span></span><br><span class="line">   <span class="comment"># 'lieping.pipelines.LiepingPipeline': 300,</span></span><br><span class="line">    <span class="string">'lieping.pipelines.LiePinMongodb'</span>: 300,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接数据库，因为我的mongodb有权限设置，所以在下面要进行用户名密码的配置</span></span><br><span class="line">user = <span class="string">"python"</span> </span><br><span class="line">password = <span class="string">"python"</span>  </span><br><span class="line">host = <span class="string">"106.12.xxx.xxx"</span> （自己服务器的IP）</span><br></pre></td></tr></table></figure>

<p>在settings配置完后，就准备写入爬虫主程序的代码编写</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import scrapy,re</span><br><span class="line">from scrapy import Request</span><br><span class="line"></span><br><span class="line">class LiepinSpider(scrapy.Spider):</span><br><span class="line">    name = <span class="string">'liepin'</span></span><br><span class="line">    allowed_domains = [<span class="string">'liepin.com'</span>]</span><br><span class="line">    <span class="comment"># start_urls = ['http://liepin.com/']</span></span><br><span class="line"></span><br><span class="line">    def start_requests(self):  <span class="comment">#重写url指定的方法</span></span><br><span class="line">        cur_page = -2</span><br><span class="line">        page = -1</span><br><span class="line">        <span class="keyword">while</span> True:</span><br><span class="line">            cur_page = cur_page + 1</span><br><span class="line">            page = page + 1</span><br><span class="line">            urls = r<span class="string">'https://www.liepin.com/zhaopin/?isAnalysis=&amp;dqs=&amp;pubTime=&amp;salary=&amp;subIndustry=&amp;industryType=&amp;compscale=&amp;key=python%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91&amp;init=-1&amp;searchType=1&amp;headckid=f55990a321cbc78b&amp;compkind=&amp;fromSearchBtn=2&amp;sortFlag=15&amp;ckid=f55990a321cbc78b&amp;degradeFlag=0&amp;jobKind=&amp;industries=&amp;clean_condition=&amp;siTag=d95cAhX-dp0D2puIzlfHZQ~fA9rXquZc5IkJpXC-Ycixw&amp;d_sfrom=search_fp_bar&amp;d_ckId=8c8c9184e4f015f91103131fb15317d8&amp;d_curPage=&#123;&#125;&amp;d_pageSize=40&amp;d_headId=8c8c9184e4f015f91103131fb15317d8&amp;curPage=&#123;&#125;'</span>.format(cur_page,page)</span><br><span class="line">            yield Request(urls,callback=self.parse)</span><br><span class="line">            <span class="keyword">if</span> page == 15:</span><br><span class="line">                <span class="built_in">break</span></span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        ul = response.xpath(r<span class="string">"//ul[@class='sojob-list']/li"</span>)</span><br><span class="line">        info = &#123;<span class="string">"con"</span>:[]&#125;</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> ul:</span><br><span class="line">            title = li.xpath(r<span class="string">".//h3/@title"</span>).get()</span><br><span class="line">            new_title = title.replace(<span class="string">'招聘'</span>,<span class="string">''</span>)</span><br><span class="line">            money = li.xpath(r<span class="string">".//span[@class='text-warning']/text()"</span>).get()</span><br><span class="line">            city = li.xpath(r<span class="string">".//p[@class='condition clearfix']//a/text()"</span>).get()</span><br><span class="line">            education =li.xpath(r<span class="string">".//span[@class='edu']/text()"</span>).get()</span><br><span class="line">            worktime = li.xpath(r<span class="string">".//span[3]/text()"</span>).get()</span><br><span class="line">            user = info[<span class="string">'con'</span>].append(&#123;<span class="string">"工作岗位"</span>:new_title,<span class="string">"薪酬"</span>:money,<span class="string">"工作地址"</span>:city,<span class="string">"学历"</span>:education,<span class="string">"工作时间"</span>:worktime&#125;)</span><br><span class="line">        <span class="built_in">return</span> info  <span class="comment">#因为上传数据库中，要以字典的形式传到piplines.py文件中</span></span><br></pre></td></tr></table></figure>

<p>爬虫代码编写好后就开始对数据进行上传，在piplines.py文件的编写</p>
<pre><code class="bash"><span class="comment"># -*- coding: utf-8 -*-</span>

<span class="comment"># Define your item pipelines here</span>
<span class="comment">#</span>
<span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>

from . import settings
from pymongo import MongoClient
from urllib.parse import quote_plus

class LiepingPipeline(object):
    def process_item(self, item, spider):
        <span class="built_in">return</span> item

class LiePinMongodb():
<span class="comment">#下面的函数名是指定的不能更改</span>
    def open_spider(self,spider):  <span class="comment">#连接MongoDB数据库的配置</span>
        url = <span class="string">"mongodb://%s:%s@%s"</span> % (
        quote_plus(settings.user), quote_plus(settings.password), quote_plus(settings.host))
        self.client = MongoClient(url)
        self.coll = self.client[<span class="string">"liepin"</span>][<span class="string">"user"</span>]
        <span class="built_in">print</span>(<span class="string">'i am center'</span>)

    def process_item(self, item, spider): <span class="comment">#爬取下来的数据进行上传</span>
        self.coll.insert(item[<span class="string">'con'</span>])
        <span class="built_in">return</span> item[<span class="string">'con'</span>]

    def colse_spider(self,spider):  <span class="comment">#关闭数据库</span>
        self.client.close()
``` bash
</code></pre>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/27/VIP视频破译/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/27/VIP视频破译/" class="post-title-link" itemprop="url">VIP视频破译</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-27 17:05:00 / Geändert am: 17:17:20" itemprop="dateCreated datePublished" datetime="2019-07-27T17:05:00+08:00">2019-07-27</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="VIP视频的API调用"><a href="#VIP视频的API调用" class="headerlink" title="VIP视频的API调用"></a>VIP视频的API调用</h2><p>本次技术主要是用到pyqt5做一个UI界面（这个是主要的技术）<br>通过用户输入的网址到后台对API接口的拼接实现VIP视频的破译，主要用到的技术不难</p>
<p>源码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">import webbrowser,re,sys</span><br><span class="line"></span><br><span class="line"><span class="comment">#vip视频破解接口</span></span><br><span class="line"><span class="comment"># url = 'https://www.administratorw.com/video.php?url='</span></span><br><span class="line"><span class="comment">#打开网页的命令</span></span><br><span class="line"><span class="comment"># webbrowser.open(url, new=0, autoraise=True)</span></span><br><span class="line"></span><br><span class="line">from PyQt5.QtWidgets import QApplication,QWidget,QToolTip, QPushButton,QLabel,QLineEdit,QGridLayout,QMessageBox,QRadioButton,QComboBox</span><br><span class="line">from PyQt5.QtGui import QFont</span><br><span class="line"></span><br><span class="line">WIGTH_SIZE = 500</span><br><span class="line">HEIGHT_SIZE = 100</span><br><span class="line">class UI(QWidget,QApplication):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.initUI()</span><br><span class="line"></span><br><span class="line">    def initUI(self):</span><br><span class="line">        label1 = QLabel(self)</span><br><span class="line">        label1.setText(<span class="string">'vip视频url：'</span>)</span><br><span class="line">        label1.move(5,50)</span><br><span class="line"></span><br><span class="line">        self.textbox = QLineEdit(self)</span><br><span class="line">        self.textbox.move(90, 50)</span><br><span class="line">        self.textbox.resize(300, 20)</span><br><span class="line"></span><br><span class="line">        btn1 = QPushButton(<span class="string">'观看'</span>, self)</span><br><span class="line">        btn1.setToolTip(<span class="string">'这是一个提交按钮，在后台拼接url'</span>)</span><br><span class="line">        btn1.move(400, 50)</span><br><span class="line">        btn1.clicked.connect(self.buttonClicked)</span><br><span class="line"></span><br><span class="line">        items = [<span class="string">'链接1'</span>,<span class="string">'链接2'</span>]</span><br><span class="line">        self.combo = QComboBox(self)</span><br><span class="line">        self.combo.addItems(items)</span><br><span class="line">        self.combo.move(10, 10)</span><br><span class="line">        self.combo.activated[str].connect(self.Link)</span><br><span class="line"></span><br><span class="line">        self.setGeometry(300, 300, WIGTH_SIZE, HEIGHT_SIZE)</span><br><span class="line">        self.setWindowTitle(<span class="string">'vip视频'</span>)</span><br><span class="line">        self.show()</span><br><span class="line"></span><br><span class="line">    def Link(self):</span><br><span class="line">        link = self.combo.currentText()</span><br><span class="line">        <span class="keyword">if</span> link == <span class="string">"链接1"</span>:</span><br><span class="line">            url = <span class="string">'https://www.administratorw.com/video.php?url='</span></span><br><span class="line">            <span class="built_in">print</span>(url)</span><br><span class="line">            <span class="built_in">return</span> url</span><br><span class="line">        <span class="keyword">elif</span> link == <span class="string">"链接2"</span>:</span><br><span class="line">            url = <span class="string">'https://jx.618g.com/?url='</span></span><br><span class="line">            <span class="built_in">print</span>(url)</span><br><span class="line">            <span class="built_in">return</span> url</span><br><span class="line"></span><br><span class="line">    def buttonClicked(self):</span><br><span class="line">        text_con = self.textbox.text()</span><br><span class="line">        <span class="keyword">if</span> text_con is <span class="string">''</span>:</span><br><span class="line">            QMessageBox.warning(self, <span class="string">"警告"</span>, <span class="string">"输入的url不能为空！"</span>, QMessageBox.Cancel)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#接口：</span></span><br><span class="line">            <span class="keyword">if</span> re.match(r<span class="string">'https://\w.*'</span>,text_con) or re.match(r<span class="string">"http://\w.*"</span>,text_con):</span><br><span class="line">                <span class="comment">#调用接口函数</span></span><br><span class="line">                links = self.Link()</span><br><span class="line">                url = links+text_con</span><br><span class="line">                webbrowser.open(url,new=0, autoraise=True)</span><br><span class="line">                self.textbox.clear()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                QMessageBox.warning(self, <span class="string">"警告"</span>, <span class="string">"您输入的url有误，请重新输入！"</span>, QMessageBox.Cancel)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    ui = UI()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/26/mongodb数据库的使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/26/mongodb数据库的使用/" class="post-title-link" itemprop="url">mongodb数据库的使用</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-26 15:54:47" itemprop="dateCreated datePublished" datetime="2019-07-26T15:54:47+08:00">2019-07-26</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-07-27 17:17:02" itemprop="dateModified" datetime="2019-07-27T17:17:02+08:00">2019-07-27</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="mongodb安装配置"><a href="#mongodb安装配置" class="headerlink" title="mongodb安装配置"></a>mongodb安装配置</h2><p>在ubuntu系统中使用以下命令安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y mongodb-org</span><br></pre></td></tr></table></figure>

<p>服务器的启动与配置</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">启动：sudo service mongodb start</span><br><span class="line">停止：sudo service mongodb stop</span><br><span class="line">重启：sudo service mongodb restart</span><br><span class="line">配置文件的位置：/etc/mongodb.conf，</span><br><span class="line">上面四个命令只有使用apt-get安装才有</span><br><span class="line">手动安装</span><br><span class="line"></span><br><span class="line">下载解压</span><br><span class="line">tar -zxvf mongodb-linux-x86_64-ubuntu1604-3.6.3.tgz</span><br><span class="line">移动到usr/<span class="built_in">local</span>目录下</span><br><span class="line">sudo mv mongodb-linux-x86_64-ubuntu1604-3.6.3 /usr/<span class="built_in">local</span>/mongodb</span><br><span class="line">把可以执行文件路径添加到<span class="variable">$PATH</span>变量下</span><br><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/mongodb/bin:<span class="variable">$PATH</span></span><br><span class="line">说明: 在 命令行执行只对当前窗口有效, 添加到.bashrc中每次启动都有效</span><br></pre></td></tr></table></figure>

<h2 id="mongodb基本命令"><a href="#mongodb基本命令" class="headerlink" title="mongodb基本命令"></a>mongodb基本命令</h2><p>操作数据库命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">查看当前的数据库：db</span><br><span class="line">查看所有的数据库：show dbs /show databases</span><br><span class="line">切换数据库：use db_name</span><br><span class="line">切换到没有的数据库, 添加数据会自动创建</span><br><span class="line">删除当前的数据库：db.dropDatabase()</span><br></pre></td></tr></table></figure>

<p>操作集合命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">不手动创建集合：</span><br><span class="line">向不存在的集合中第⼀次加⼊数据时， 集合会被创建出来</span><br><span class="line">手动创建结合(了解)：</span><br><span class="line"></span><br><span class="line">db.createCollection(name,options)</span><br><span class="line">db.createCollection(<span class="string">"stu"</span>)</span><br><span class="line">db.createCollection(<span class="string">"sub"</span>, &#123; capped : <span class="literal">true</span>, size : 10 &#125; )</span><br><span class="line">参数capped： 默认值为<span class="literal">false</span>表示不设置上限,值为<span class="literal">true</span>表示设置上限</span><br><span class="line">参数size： 当capped值为<span class="literal">true</span>时， 需要指定此参数， 表示上限,单位为字节</span><br><span class="line">当档达到上限时， 会将之前的数据覆盖， 最早添加的数据移出, 其余上移, 最后添加在最后一条</span><br><span class="line">查看集合：show collections</span><br><span class="line">删除集合：db.集合名称.drop()</span><br></pre></td></tr></table></figure>

<h2 id="mongodb中的数据类型"><a href="#mongodb中的数据类型" class="headerlink" title="mongodb中的数据类型"></a>mongodb中的数据类型</h2><p>String： 字符串， 最常使用 必须是有效的UTF-8<br>Boolean： 存储多个布尔值， true或false<br>Integer： 整数可以是32位或64位， 这取决于服务器<br>Double： 存储浮点值<br>Null： 存储Null值<br>Timestamp： 时间戳， 表示从1970-1-1到现在的总秒数<br>Date： 存储当前日期或时间的UNIX时间格式</p>
<h2 id="mongodb的增删改查"><a href="#mongodb的增删改查" class="headerlink" title="mongodb的增删改查"></a>mongodb的增删改查</h2><p>插入数据</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">db.集合名称.insert(document)</span><br><span class="line">db.stu.insert(&#123;name:<span class="string">'gj'</span>,gender:1&#125;)</span><br><span class="line">db.stu.insert(&#123;_id:<span class="string">"20170101"</span>,name:<span class="string">'gj'</span>,gender:1&#125;)</span><br><span class="line">插入数据时，如果不指定_id参数， MongoDB会为自动分配ID</span><br><span class="line">插入单条指定为字典, 插入多条指定为列表</span><br></pre></td></tr></table></figure>

<p>保存</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">db.集合名称.save(document)</span><br><span class="line">如果_id已经存在则修改， 如果⽂档的_id不存在则添加</span><br><span class="line">区别于: insert如果存在直接报错</span><br></pre></td></tr></table></figure>

<p>简单查询</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.集合名称.find()</span><br></pre></td></tr></table></figure>

<p>更新</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">语法: db.集合名称.update(&lt;query&gt; ,&lt;update&gt;,&#123;multi: &lt;boolean&gt;&#125;)</span><br><span class="line">参数query:查询条件</span><br><span class="line">参数update:更新操作符</span><br><span class="line">参数multi:可选， 默认是<span class="literal">false</span>，表示只更新找到的第⼀条记录， 值为<span class="literal">true</span>表示把满⾜条件的⽂档全部更新</span><br><span class="line">举例:</span><br><span class="line">db.stu.update(&#123;name:<span class="string">'hr'</span>&#125;,&#123;name:<span class="string">'mnc'</span>&#125;) 更新一条,没有更新的字段会丢弃.</span><br><span class="line">db.stu.update(&#123;name:<span class="string">'hr'</span>&#125;,&#123;<span class="variable">$set</span>:&#123;name:<span class="string">'hys'</span>&#125;&#125;) 更新一条</span><br><span class="line">db.stu.update(&#123;&#125;,&#123;<span class="variable">$set</span>:&#123;gender:0&#125;&#125;,&#123;multi:<span class="literal">true</span>&#125;) 更新全部</span><br><span class="line">注意：<span class="string">"multi update only works with $ operators"</span> 更新全部,必须使用<span class="variable">$set</span></span><br></pre></td></tr></table></figure>

<p>删除</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法: db.集合名称.remove(&lt;query&gt;,&#123;justOne: &lt;boolean&gt;&#125;)</span><br><span class="line">参数query:可选，删除数据的条件</span><br><span class="line">参数justOne:可选， 如果设为<span class="literal">true</span>或1， 则只删除⼀条， 默认<span class="literal">false</span>， 表示删除多条</span><br></pre></td></tr></table></figure>


          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/25/Selenium模拟请求爬取数据与防爬/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/25/Selenium模拟请求爬取数据与防爬/" class="post-title-link" itemprop="url">Selenium模拟请求爬取数据与反扒机制</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-25 13:41:14" itemprop="dateCreated datePublished" datetime="2019-07-25T13:41:14+08:00">2019-07-25</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-07-27 17:17:06" itemprop="dateModified" datetime="2019-07-27T17:17:06+08:00">2019-07-27</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Selenium简介"><a href="#Selenium简介" class="headerlink" title="Selenium简介"></a>Selenium简介</h2><p>Selenium是一种自动化测试工具，它支持各种浏览器，包括 Chrome，Safari，Firefox 等主流界面式浏览器，如果你在这些浏览器里面安装一个 Selenium 的插件，那么便可以方便地实现Web界面的测试。换句话说叫 Selenium 支持这些浏览器驱动。<br>我们可以用Selenium来模拟正常用户浏览服务器的请求，实现简要的数据爬取。</p>
<p>Selenium 安装</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure>

<p>ChromeDriver下载安装:<br>注意下载的版本号要支持你的浏览器<br>淘宝镜像<br>ChromeDriver淘宝镜像：<a href="http://npm.taobao.org/" target="_blank" rel="noopener">http://npm.taobao.org/</a><br>注意查看chromedriver支持的版本 ：<a href="https://npm.taobao.org/mirrors/chromedriver/2.38/notes.txt" target="_blank" rel="noopener">https://npm.taobao.org/mirrors/chromedriver/2.38/notes.txt</a><br>Linux 或 Mac 解压后直接拷贝到usr/local/bin 或 usr/bin 下即可; 也可以制作软连接放到上面的两个路径下<br>在Linux或Mac中如果报关于Permission的错误, 是因为chromedriver这个文件没有执行权限, 就修改chromedriver文件的权限为 777<br>chmod 777 chromedriver</p>
<h2 id="Selenium入门"><a href="#Selenium入门" class="headerlink" title="Selenium入门"></a>Selenium入门</h2><p>加载网页：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">driver = webdriver.Chrome()  如果是Windows()中传入driver的路径: “c:…/pantomjs.exe”</span><br><span class="line">driver.get(<span class="string">"http://www.baidu.com/"</span>) <span class="comment"># 加载页面 百度首页</span></span><br><span class="line">driver.save_screenshot(<span class="string">"baidu.png"</span>) <span class="comment"># 保存当前界面</span></span><br></pre></td></tr></table></figure>

<p>定位和操作：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.find_element_by_id(“kw”).send_keys(“python”)   <span class="comment"># 找到id为kw的输入框, 填写: python</span></span><br><span class="line">driver.find_element_by_id(<span class="string">"su"</span>).click()  <span class="comment"># 找到id为su的, 进行单击</span></span><br></pre></td></tr></table></figure>

<p>查看请求信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">driver.page_source   <span class="comment"># 获取页面的源码</span></span><br><span class="line">driver.get_cookies() <span class="comment"># 获取cookie信息</span></span><br><span class="line">driver.current_url   <span class="comment"># 获取当前的URL</span></span><br></pre></td></tr></table></figure>

<p>这个比较少用到，主要看需求吧</p>
<p>退出</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.close() <span class="comment">#退出当前页面</span></span><br><span class="line">driver.quit() <span class="comment">#退出浏览器</span></span><br></pre></td></tr></table></figure>

<h2 id="Selenium中操作cookie的方法"><a href="#Selenium中操作cookie的方法" class="headerlink" title="Selenium中操作cookie的方法"></a>Selenium中操作cookie的方法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;cookie[‘name’]: cookie[‘value’] <span class="keyword">for</span> cookie <span class="keyword">in</span> driver.get_cookies()&#125;</span><br><span class="line">driver.delete_cookie(<span class="string">"CookieName"</span>)</span><br><span class="line">driver.delete_all_cookies()</span><br></pre></td></tr></table></figure>

<h2 id="selenium定位页面元素"><a href="#selenium定位页面元素" class="headerlink" title="selenium定位页面元素"></a>selenium定位页面元素</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">find_element_by_id (返回一个,如果没有就报错了)</span><br><span class="line">find_elements_by_xpath （返回一个列表,如果没有就返回一个空列表）</span><br><span class="line">find_elements_by_link_text (根据文本内容返回元素列表, 如果没有返回空列表)</span><br><span class="line">find_elements_by_partial_link_text (根据文件部分内容返回元素列表, 如果没有返回空列表)</span><br><span class="line">find_elements_by_tag_name(根据标签名[节点名]返回元素元素列表, 如果没有返回空列表)</span><br><span class="line">find_elements_by_class_name(根据class属性对应值范围元素列表, 如果没有返回空列表)</span><br><span class="line">find_elements_by_css_selector(根据css选择器返回元素列表, 如果没有返回空列表)</span><br></pre></td></tr></table></figure>

<p>具体用法自行百度搜索</p>
<p>注意点:</p>
<p>find_element 和find_elements的区别：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find_element: 返回找到第一个元素,如果没有报错</span><br><span class="line">find_elements: 返回找到的所有元素列表, 如果没有找到返回空列表</span><br></pre></td></tr></table></figure>

<p>by_link_text和by_partial_link_text的区别：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">by_link_text: 全部文本都一样</span><br><span class="line">by_partial_link_text: 包含某个文本</span><br></pre></td></tr></table></figure>

<p>by_link_text这个平常也很少用<br>by_xpath只能获取元素, 要获取属性和文本需要使用get_attribute(属性名) 和.text</p>
<h2 id="Selenium处理反扒的措施"><a href="#Selenium处理反扒的措施" class="headerlink" title="Selenium处理反扒的措施"></a>Selenium处理反扒的措施</h2><p>解决办法就是——用webdirver接管我们自己打开的浏览器，然后再进行登录操作。</p>
<p>文章参考：<br>Selenium的反扒环境配置：<a href="https://blog.csdn.net/qq_42206477/article/details/86477446?utm_source=app" target="_blank" rel="noopener">https://blog.csdn.net/qq_42206477/article/details/86477446?utm_source=app</a><br>具体的接管方法：<a href="https://www.cnblogs.com/HJkoma/p/9936434.html" target="_blank" rel="noopener">https://www.cnblogs.com/HJkoma/p/9936434.html</a></p>
<h2 id="用Selenium爬取拉钩python的所有职位信息"><a href="#用Selenium爬取拉钩python的所有职位信息" class="headerlink" title="用Selenium爬取拉钩python的所有职位信息"></a>用Selenium爬取拉钩python的所有职位信息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver import ActionChains</span><br><span class="line">import time,json,csv,re</span><br><span class="line"></span><br><span class="line">class LaGou():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.drive = webdriver.Chrome()</span><br><span class="line">        self.ul = self.drive.get(r<span class="string">'https://www.lagou.com/jobs/list_java?city=%E5%B9%BF%E5%B7%9E&amp;cl=false&amp;fromSearch=true&amp;labelWords=&amp;suginput='</span>)</span><br><span class="line"></span><br><span class="line">    def gundong(self):  <span class="comment">#自动滚动页面</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(0, 10500, 500):</span><br><span class="line">            jsCode = <span class="string">"document.documentElement.scrollTop=%s"</span> % i</span><br><span class="line">            self.drive.execute_script(jsCode)</span><br><span class="line">            time.sleep(0.3)</span><br><span class="line"></span><br><span class="line">    def get_info(self):  <span class="comment">#获取页面详细信息</span></span><br><span class="line">        ul = self.drive.find_elements_by_xpath(r<span class="string">'//*[@id="s_position_list"]/ul//li'</span>)</span><br><span class="line">        user_info = []</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> ul:</span><br><span class="line">            work = li.find_element_by_xpath(r<span class="string">".//h3"</span>).text</span><br><span class="line">            money = li.find_element_by_xpath(r<span class="string">".//div[@class='li_b_l']/span[@class='money']"</span>).text</span><br><span class="line">            xueli1 = li.find_element_by_xpath(r<span class="string">".//div[@class='p_bot']/div"</span>).text</span><br><span class="line">            xueli = re.search(r<span class="string">'/ (\w.*)'</span>, xueli1).group(1)</span><br><span class="line">            company_name = li.find_element_by_xpath(r<span class="string">".//div[@class='company_name']/a"</span>).text</span><br><span class="line">            user_info.append([work,money,xueli,company_name])</span><br><span class="line">        <span class="built_in">print</span>(user_info)</span><br><span class="line">        <span class="built_in">return</span> user_info</span><br><span class="line"></span><br><span class="line">    def mouser_clink(self):  <span class="comment">#鼠标点击事件</span></span><br><span class="line">        ac =self.drive.find_element_by_xpath(r<span class="string">"//div[@class='pager_container']/span[@class='pager_next ']"</span>)</span><br><span class="line">        ActionChains(self.drive).move_to_element(ac).click(ac).perform()</span><br><span class="line">    </span><br><span class="line">    def save(self,info):    <span class="comment">#保存数据，保存成Excel表中</span></span><br><span class="line">        with open(<span class="string">'java.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) as f:</span><br><span class="line">            writer = csv.writer(f)</span><br><span class="line">            writer.writerow([<span class="string">"工种"</span>,<span class="string">"薪酬"</span>,<span class="string">"学历"</span>,<span class="string">"公司名"</span>])</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> info:</span><br><span class="line">                writer.writerows(info)<span class="comment"># 还可以写入多行</span></span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(30):</span><br><span class="line">            self.gundong()</span><br><span class="line">            info = self.get_info()</span><br><span class="line">            self.save(info)</span><br><span class="line">            self.mouser_clink()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    lagou = LaGou()</span><br><span class="line">    lagou.run()</span><br></pre></td></tr></table></figure>

<h2 id="用Selenium爬取拼多多（添加对selenium的反扒）"><a href="#用Selenium爬取拼多多（添加对selenium的反扒）" class="headerlink" title="用Selenium爬取拼多多（添加对selenium的反扒）"></a>用Selenium爬取拼多多（添加对selenium的反扒）</h2><p>项目分析：<br>拼多多这个网站的反扒机制比较强烈，个人研究了一天了终于爬取部分数据。拼多多的网页版界面已经不再维护了，所以我换了个url<br>访问的url：<a href="http://mobile.yangkeduo.com/" target="_blank" rel="noopener">http://mobile.yangkeduo.com/</a></p>
<p>前提是要配置好对selenium的接管操作，每次运行时都要在cmd窗口里运行：chrome.exe –remote-debugging-port=9222 –user-data-dir=”C:\selenum\AutomationProfile”</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver import ChromeOptions</span><br><span class="line">from selenium.webdriver.chrome.options import Options</span><br><span class="line">import time,requests,csv</span><br><span class="line"></span><br><span class="line">class Pinduoduo():</span><br><span class="line">    def __init__(self,con):</span><br><span class="line">        self.chrome_options = Options()</span><br><span class="line">        self.chrome_options.add_experimental_option(<span class="string">"debuggerAddress"</span>, <span class="string">"127.0.0.1:9222"</span>)</span><br><span class="line">        self.chrome_driver = r<span class="string">"C:\Users\Administrator.SKY-20190217ZDF\AppData\Local\Google\Chrome\Application\chrome.exe"</span></span><br><span class="line">        self.driver = webdriver.Chrome(options=self.chrome_options)</span><br><span class="line">        self.ul = self.driver.get(r<span class="string">"http://mobile.yangkeduo.com/search_result.html?search_key=&#123;&#125;"</span>.format(con))</span><br><span class="line"></span><br><span class="line">    def get_info(self):</span><br><span class="line">        self.urls = self.driver.find_elements_by_xpath(r<span class="string">"//div[@class='_2EdaAb7m']/div"</span>)</span><br><span class="line">        user_info = []</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> self.urls:</span><br><span class="line">            try:</span><br><span class="line">                images = li.find_element_by_xpath(r<span class="string">".//div[@class='bqyzKuVp _2nXx5SjD']/img"</span>).get_attribute(<span class="string">"src"</span>)</span><br><span class="line">                title = li.find_element_by_xpath(r<span class="string">".//div[@class='troiqcp4 OSSkI8pu']"</span>).text</span><br><span class="line">                money = li.find_element_by_xpath(r<span class="string">".//div[@class='W2aG482G']"</span>).text</span><br><span class="line">                buysum = li.find_element_by_xpath(r<span class="string">".//span[@class='_2zosSFdU']"</span>).text</span><br><span class="line">                user_info.append([images,title,money,buysum])</span><br><span class="line">            except Exception:</span><br><span class="line">                pass</span><br><span class="line">        <span class="built_in">print</span>(user_info)</span><br><span class="line">        <span class="built_in">return</span> user_info</span><br><span class="line"></span><br><span class="line">    def save(self,info):</span><br><span class="line">        with open(<span class="string">'pinduoduo.csv'</span>, <span class="string">'a'</span>, newline=<span class="string">''</span>,encoding=<span class="string">"utf-8"</span>) as f:</span><br><span class="line">            writer = csv.writer(f)</span><br><span class="line">            writer.writerows(info)<span class="comment"># 还可以写入多行</span></span><br><span class="line"></span><br><span class="line">    def gun(self):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(0, 500000, 1000):</span><br><span class="line">            <span class="built_in">print</span>(i)</span><br><span class="line">            jsCode = <span class="string">"document.documentElement.scrollTop=%s"</span> % i</span><br><span class="line">            self.driver.execute_script(jsCode)</span><br><span class="line">            time.sleep(1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pin = Pinduoduo(<span class="string">"小白鞋"</span>)</span><br><span class="line">    pin.gun()</span><br><span class="line">    info = pin.get_info()</span><br><span class="line">    pin.save(info)</span><br></pre></td></tr></table></figure>

<p>如果显示了登录界面就是你访问的次数多了。。。。。。。</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/24/爬虫中的xpath应用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/24/爬虫中的xpath应用/" class="post-title-link" itemprop="url">爬虫中的xpath应用</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-24 10:58:39 / Geändert am: 11:19:59" itemprop="dateCreated datePublished" datetime="2019-07-24T10:58:39+08:00">2019-07-24</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="xpath-是什么"><a href="#xpath-是什么" class="headerlink" title="xpath 是什么"></a>xpath 是什么</h2><p>xpath简单来说就是可以通过元素定位的方式获取到想要的标签字段。XPath (XML Path Language) 是一门在 HTML\XML 文档中查找信息的语言，可用来在 HTML\XML 文档中对元素和属性进行遍历。<br>W3School官方文档：<a href="http://www.w3school.com.cn/xpath/index.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/xpath/index.asp</a></p>
<h2 id="安装-xpath"><a href="#安装-xpath" class="headerlink" title="安装 xpath"></a>安装 xpath</h2><p>在安装xpath的时候要先安装lxml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install lxml</span><br></pre></td></tr></table></figure>

<h2 id="导入lxml包"><a href="#导入lxml包" class="headerlink" title="导入lxml包"></a>导入lxml包</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from lxml import etree</span><br></pre></td></tr></table></figure>

<p>利用etree.HTML，将字符串转化为Element对象,Element对象具有xpath的方法,返回结果的列表，能够接受bytes类型的数据和str类型的数据</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">html = etree.HTML(text) </span><br><span class="line">ret_list = html.xpath(<span class="string">"xpath字符串"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="xpath-的基本使用"><a href="#xpath-的基本使用" class="headerlink" title="xpath 的基本使用"></a>xpath 的基本使用</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">选择所有的h1下的文本</span><br><span class="line">//h1/text()</span><br><span class="line">获取所有的a标签的href</span><br><span class="line">//a/@href</span><br><span class="line">获取html下的head下的title的文本</span><br><span class="line">/html/head/title/text()</span><br><span class="line">获取html下的head下的link标签的href</span><br><span class="line">/html/head/link/@href</span><br></pre></td></tr></table></figure>

<h2 id="查找特定的节点"><a href="#查找特定的节点" class="headerlink" title="查找特定的节点"></a>查找特定的节点</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//title[@lang=<span class="string">"eng"</span>]	选择lang属性值为eng的所有title元素</span><br><span class="line">/bookstore/book[1]	选取属于 bookstore 子元素的第一个 book 元素。</span><br><span class="line">/bookstore/book[last()]	选取属于 bookstore 子元素的最后一个 book 元素。</span><br><span class="line">/bookstore/book[last()-1]	选取属于 bookstore 子元素的倒数第二个 book 元素。</span><br><span class="line">/bookstore/book[position()&gt;1]	选择bookstore下面的book元素，从第二个开始选择</span><br><span class="line">//book/title[text()=<span class="string">'Harry Potter'</span>]	选择所有book下的title元素，仅仅选择文本为Harry Potter的title元素</span><br><span class="line">/bookstore/book[price&gt;35.00]/title	选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。</span><br></pre></td></tr></table></figure>

<h2 id="xpath的学习重点"><a href="#xpath的学习重点" class="headerlink" title="xpath的学习重点"></a>xpath的学习重点</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">定位元素</span><br><span class="line">路径分割符</span><br><span class="line">/: 单级查找</span><br><span class="line">用在最前面表示当前文档的根节点(标签)</span><br><span class="line">只能用于分割相邻的父子节点(标签)</span><br><span class="line">如: /html/head/meta</span><br><span class="line">//: 多级查找</span><br><span class="line">//a 查找整个文档中所有的a标签</span><br><span class="line">div//a 查找该div下所有的a标签</span><br><span class="line">过滤(筛选)元素</span><br><span class="line">a[@href]: 选取有herf属性的标签</span><br><span class="line">div[@id=<span class="string">'page'</span>]: 选取class属性为page的div标签</span><br><span class="line">a[text()=<span class="string">'下一页&gt;'</span>]: 选取文本内容为下一页的a标签</span><br><span class="line">a[2]: 选取匹配列表中第二个元素</span><br><span class="line">a[last()]: 选取匹配列表中最后一个</span><br><span class="line">a[position()&lt;4] 选取匹配列表中前3个</span><br><span class="line">a[position()&gt;4] 选取匹配列表中第4元素以后的</span><br><span class="line">获取内容</span><br><span class="line">a/text() 获取a标签中的文本内容</span><br><span class="line">a//text() 获取a标签中以及所有子类标签的内容</span><br><span class="line">a/@href 获取a标签中herf属性的值</span><br></pre></td></tr></table></figure>

<h2 id="案例实验"><a href="#案例实验" class="headerlink" title="案例实验"></a>案例实验</h2><p>此爬虫写了很久了，网站应该有更新，如果直接复制可能使用不了，建议先看懂思路在修改源码</p>
<p>爬取包图网的短视频</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import requests,os</span><br><span class="line">from lxml import etree</span><br><span class="line">main_html = requests.get(r<span class="string">'https://ibaotu.com/shipin/'</span>)</span><br><span class="line">main_html.encoding = <span class="string">'utf-8'</span></span><br><span class="line">xml = etree.HTML(main_html.text)</span><br><span class="line">src_link = xml.xpath(<span class="string">'//div[@class="video-play"]/video/@src'</span>)</span><br><span class="line">title_link = xml.xpath(<span class="string">'//span[@class="video-title"]/text()'</span>)</span><br><span class="line">file = os.mkdir(r<span class="string">'./包图网视频'</span>)</span><br><span class="line"><span class="keyword">for</span> title,src <span class="keyword">in</span> zip(title_link,src_link):</span><br><span class="line">    link = requests.get(<span class="string">'https:'</span>+src)</span><br><span class="line">    with open(r<span class="string">'./包图网视频/'</span>+title+<span class="string">'.mp4'</span>,<span class="string">'wb'</span>) as f :</span><br><span class="line">        f.write(link.content)</span><br><span class="line">        <span class="built_in">print</span>(title)</span><br></pre></td></tr></table></figure>

<p>以后博主会尽量退出有关视频的爬取与对手机app的数据采集，敬请留意更新！</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/23/requests伪装与代理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/23/requests伪装与代理/" class="post-title-link" itemprop="url">requests伪装与代理</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-23 14:17:27 / Geändert am: 14:45:57" itemprop="dateCreated datePublished" datetime="2019-07-23T14:17:27+08:00">2019-07-23</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="requests伪装"><a href="#requests伪装" class="headerlink" title="requests伪装"></a>requests伪装</h2><p>requests伪装主要是伪装成浏览器进行一个网页爬取数据，常用的是通过“user-agent”，“referer”等请求头的参数进行一个伪装的访问请求。“user-agent”是告诉浏览器客户端的身份，所以在请求网页的同时要携带上客户端身份伪装。</p>
<h2 id="requests代理"><a href="#requests代理" class="headerlink" title="requests代理"></a>requests代理</h2><p>在爬虫时，我们不能用同一个IP进行爬取信息，一来容易被服务器发现自己的身份。二来如果被服务器发现你是一个爬虫，那么在服务器的黑名单中就会添加上你的IP，禁止了你IP对浏览器的访问。这时候我们就会用到代理服务</p>
<p>如何在requests中使用代理：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxies = &#123;</span><br><span class="line">   <span class="string">"http"</span>:<span class="string">"http://ip:端口号"</span></span><br><span class="line">   <span class="string">"https"</span>:<span class="string">"https://ip:端口号"</span></span><br><span class="line">&#125;</span><br><span class="line">request.get(url, proxies=proxies)</span><br></pre></td></tr></table></figure>

<p>代理的IP地址可在快代理平台中进行搜索免费IP，不过多数都已经不能使用了</p>
<p>如果是购买的IP代理则通过如下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxies = &#123;</span><br><span class="line">   <span class="string">"http"</span>:<span class="string">"http://username:password@ip:端口号"</span></span><br><span class="line">   <span class="string">"https"</span>: <span class="string">"https://username:password@ip:端口号"</span></span><br><span class="line">&#125;</span><br><span class="line">request.get(url, proxies=proxies)</span><br></pre></td></tr></table></figure>

<h2 id="使用代理IP池生成随机代理"><a href="#使用代理IP池生成随机代理" class="headerlink" title="使用代理IP池生成随机代理"></a>使用代理IP池生成随机代理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">import requests</span><br><span class="line"><span class="comment"># 1. 准备代理列表</span></span><br><span class="line">proxies = [</span><br><span class="line">    &#123;<span class="string">'http'</span>: <span class="string">'121.8.98.198:80'</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'http'</span>: <span class="string">'39.108.234.144:80'</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'http'</span>: <span class="string">'125.120.201.68:808'</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'http'</span>: <span class="string">'120.24.216.39:60443'</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'http'</span>: <span class="string">'121.8.98.198:80'</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'http'</span>: <span class="string">'121.8.98.198:80'</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 随机选出一个代理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(0, 10):</span><br><span class="line">    proxy = random.choice(proxies)</span><br><span class="line">    <span class="built_in">print</span>(proxy)</span><br><span class="line">    try:</span><br><span class="line">        response = requests.get(<span class="string">"http://www.baidu.com"</span>, proxies=proxy, timeout=3)</span><br><span class="line">        <span class="built_in">print</span>(response.status_code)</span><br><span class="line">    except Exception as ex:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"代理有问题: %s"</span> % proxy)</span><br></pre></td></tr></table></figure>

<p>测试代理IP的可用性</p>
<h2 id="通过伪装的用户身份与代理爬取果壳问答"><a href="#通过伪装的用户身份与代理爬取果壳问答" class="headerlink" title="通过伪装的用户身份与代理爬取果壳问答"></a>通过伪装的用户身份与代理爬取果壳问答</h2><p>源代码如下，仅供参考。<br>基于OOP编程的思想编写代码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import requests,json,random</span><br><span class="line">from lxml import etree</span><br><span class="line"></span><br><span class="line">class GuoKe():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.num = 0</span><br><span class="line">        self.headers = [&#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1'</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (iPad; CPU OS 11_0 like Mac OS X) AppleWebKit/604.1.34 (KHTML, like Gecko) Version/11.0 Mobile/15A5341f Safari/604.1'</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Linux; Android 8.0; Pixel 2 Build/OPD3.170816.012) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Mobile Safari/537.36'</span></span><br><span class="line">        &#125;</span><br><span class="line">        ]</span><br><span class="line">        self.proxies = [</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'121.8.98.198:80'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'39.108.234.144:80'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'125.120.201.68:808'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'120.24.216.39:60443'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'121.8.98.198:80'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'121.8.98.198:80'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>:<span class="string">'123.206.30.254:8118'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'115.210.24.183:9000'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'183.129.207.86:14002'</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'http'</span>: <span class="string">'183.129.207.89:27727'</span>&#125;,</span><br><span class="line"></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">    def urls(self):  <span class="comment">#获取url</span></span><br><span class="line">        url_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(1,101):</span><br><span class="line">            url = <span class="string">"https://www.guokr.com/ask/highlight/?page=%s"</span>%i</span><br><span class="line">            url_list.append(url)</span><br><span class="line">        <span class="built_in">return</span> url_list</span><br><span class="line"></span><br><span class="line">    def get_info(self,url):  <span class="comment">#得到URL后进行请求并获取信息</span></span><br><span class="line">        proxy = random.choice(self.proxies)</span><br><span class="line">        headers = random.choice(self.headers)</span><br><span class="line">        <span class="comment"># print(proxy)</span></span><br><span class="line">        <span class="comment"># print(headers)</span></span><br><span class="line">        main_html = requests.get(url,proxies=proxy,headers=headers)</span><br><span class="line">        main_info = etree.HTML(main_html.text)</span><br><span class="line">        lists = main_info.xpath(<span class="string">'//div[@class="gmain"]/ul[2]//li'</span>)</span><br><span class="line">        info = []</span><br><span class="line">        <span class="keyword">for</span> list <span class="keyword">in</span> lists:</span><br><span class="line">            title = list.xpath(<span class="string">".//h2/a/text()"</span>)</span><br><span class="line">            answer_url = list.xpath(<span class="string">".//h2/a/@href"</span>)</span><br><span class="line">            user_info = &#123;<span class="string">"title"</span>:title,<span class="string">"url"</span>:answer_url&#125;</span><br><span class="line">            info.append(user_info)</span><br><span class="line"></span><br><span class="line">        self.num += 1</span><br><span class="line">        <span class="comment"># print(self.num)</span></span><br><span class="line">        <span class="comment"># print(len(info))</span></span><br><span class="line">        <span class="built_in">return</span> info</span><br><span class="line"></span><br><span class="line">    def save(self,info):</span><br><span class="line">        json_str = json.dumps(info,indent=4,ensure_ascii=False)</span><br><span class="line">        with open(<span class="string">'./果壳问答.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>)as f:</span><br><span class="line">            f.write(json_str)</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        urls = self.urls()</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            time.sleep(1)</span><br><span class="line">            html = self.get_info(url)</span><br><span class="line">            self.save(html)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    guoke = GuoKe()</span><br><span class="line">    guoke.run()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/22/hexo 看板娘的设置/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/22/hexo 看板娘的设置/" class="post-title-link" itemprop="url">hexo 看板娘的设置</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-22 22:02:46 / Geändert am: 22:29:17" itemprop="dateCreated datePublished" datetime="2019-07-22T22:02:46+08:00">2019-07-22</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="对live2D的设置（看板娘）"><a href="#对live2D的设置（看板娘）" class="headerlink" title="对live2D的设置（看板娘）"></a>对live2D的设置（看板娘）</h2><p>生成板娘的代码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;% raw %&#125;</span><br><span class="line">	&lt;title&gt;Live2D！把可爱的看板娘扑捉到你的博客去吧！&lt;/title&gt;</span><br><span class="line">    &lt;link rel=<span class="string">"stylesheet"</span> href=<span class="string">"/live2d/css/live2d.css"</span> /&gt;</span><br><span class="line">&lt;div id=<span class="string">"landlord"</span>&gt;</span><br><span class="line">    &lt;div class=<span class="string">"message"</span> style=<span class="string">"opacity:0"</span>&gt;&lt;/div&gt;</span><br><span class="line">    &lt;canvas id=<span class="string">"live2d"</span> width=<span class="string">"280"</span> height=<span class="string">"250"</span> class=<span class="string">"live2d"</span>&gt;&lt;/canvas&gt;</span><br><span class="line">    &lt;div class=<span class="string">"hide-button"</span>&gt;隐藏&lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">"text/javascript"</span> src=<span class="string">"https://cdn.bootcss.com/jquery/2.2.4/jquery.min.js"</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    var message_Path = <span class="string">'/live2d/'</span></span><br><span class="line">    var home_Path = <span class="string">'https://www.baidu.com/'</span></span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">"text/javascript"</span> src=<span class="string">"/live2d/js/live2d.js"</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">"text/javascript"</span> src=<span class="string">"/live2d/js/message.js"</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    loadlive2d(<span class="string">"live2d"</span>, <span class="string">"/live2d/model/tia/model.json"</span>);</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&#123;% endraw %&#125;</span><br></pre></td></tr></table></figure>

<p>转载：<br>b站视频教学：<a href="https://www.bilibili.com/video/av24869594?from=search&amp;seid=1951733394688932441" target="_blank" rel="noopener">https://www.bilibili.com/video/av24869594?from=search&amp;seid=1951733394688932441</a></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/22/requests基础操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/22/requests基础操作/" class="post-title-link" itemprop="url">requests基础操作</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-22 20:45:31" itemprop="dateCreated datePublished" datetime="2019-07-22T20:45:31+08:00">2019-07-22</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-07-24 11:17:06" itemprop="dateModified" datetime="2019-07-24T11:17:06+08:00">2019-07-24</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="个人博客"><a href="#个人博客" class="headerlink" title="个人博客"></a>个人博客</h2><p>欢迎来到ssc的个人博客平台，此平台会推送有关python爬虫的案列等</p>
<h3 id="安装requests模块"><a href="#安装requests模块" class="headerlink" title="安装requests模块"></a>安装requests模块</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install requests</span><br></pre></td></tr></table></figure>

<h3 id="导入的包"><a href="#导入的包" class="headerlink" title="导入的包"></a>导入的包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ import requests</span><br></pre></td></tr></table></figure>

<p>主要用于用户请求网页url链接</p>
<h3 id="requests-GET-请求例子"><a href="#requests-GET-请求例子" class="headerlink" title="requests GET 请求例子"></a>requests GET 请求例子</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ import requests</span><br><span class="line">$ url = r<span class="string">"https://www.baidu.com"</span></span><br><span class="line">$ res = requests.get(url)</span><br></pre></td></tr></table></figure>

<p>请求百度的url链接，其中的res是返回一个状态码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ html = res.text</span><br></pre></td></tr></table></figure>

<p>html是打印出res的文本信息，显示网页源代码</p>
<h3 id="requests-POST-请求例子"><a href="#requests-POST-请求例子" class="headerlink" title="requests POST 请求例子"></a>requests POST 请求例子</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">说明: http://httpbin.org 是一个专门用于测试http请求网站</span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'name'</span>:<span class="string">'ssc'</span></span><br><span class="line">    &#125;</span><br><span class="line">response = requests.post(r<span class="string">'http://httpbin.org/post'</span>,data=data)</span><br><span class="line"><span class="built_in">print</span>(response.content.decode())</span><br></pre></td></tr></table></figure>

<p>如果是post请求则要携带data参数。</p>
<h3 id="response的常用属性"><a href="#response的常用属性" class="headerlink" title="response的常用属性"></a>response的常用属性</h3><p>response = requests.get(url)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">response.text    显示网页源代码</span><br><span class="line">respones.content 二进制形式的响应数据</span><br><span class="line">response.status_code 响应状态吗</span><br><span class="line">response.headers 响应头</span><br><span class="line">response.request.headers 请求头</span><br></pre></td></tr></table></figure>

<p>response.text 和response.content的区别</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">response.text</span><br><span class="line">类型：str</span><br><span class="line">解码类型： 根据HTTP头部对响应的编码作出有根据的推测，推测的文本编码</span><br><span class="line">如何修改编码方式：response.encoding=”gbk”</span><br><span class="line"></span><br><span class="line">response.content</span><br><span class="line">类型：bytes</span><br><span class="line">解码类型： 没有指定</span><br><span class="line">如何修改编码方式：response.content.deocde(“utf8”)</span><br><span class="line"></span><br><span class="line">更推荐使用response.content.deocde()的方式获取响应的html页面</span><br></pre></td></tr></table></figure>

<h2 id="requests二进制写入数据"><a href="#requests二进制写入数据" class="headerlink" title="requests二进制写入数据"></a>requests二进制写入数据</h2><p>下载图片到本地</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入requests模块</span></span><br><span class="line">import requests</span><br><span class="line"><span class="comment"># 2. 发送请求获取二进制数据(bytes)</span></span><br><span class="line">respone =  requests.get(<span class="string">"http://imgsrc.baidu.com/image/c0%3Dpixel_huitu%2C0%2C0%2C294%2C40/sign=098c3f828cd6277ffd1f3a7841407a5c/3c6d55fbb2fb4316e3afd1432ba4462309f7d353.jpg"</span>)</span><br><span class="line"><span class="comment"># 获取二进制数据; 注意: 这里不要解码, 因为图片,视频等文件都是二进制的不是文本,不需要解码</span></span><br><span class="line"><span class="comment"># data = respone.content</span></span><br><span class="line"><span class="comment"># 3. 把数据写入文件</span></span><br><span class="line">with open(<span class="string">"壁纸.jpg"</span>, <span class="string">"wb"</span>) as f:</span><br><span class="line">    f.write(respone.content)</span><br></pre></td></tr></table></figure>

<p>图片是利用二进制写入，拿取得数据通过.content进行二进制写入</p>
<h3 id="requests携带请求头进行访问"><a href="#requests携带请求头进行访问" class="headerlink" title="requests携带请求头进行访问"></a>requests携带请求头进行访问</h3><p>首先我们要弄清楚一个问题就是为什么要携带请求头进行访问url<br>站主个人理解：携带请求头可以伪装成浏览器对服务器请求，如果不带请求头则表示自己是一个爬虫，容易被服务器识别出来而被拒绝访问。<br>列如：我们上学时要带校卡穿上校服，如果没有这两个条件时，学校则会认为我们不是一个学生。就会禁止我们进入学校。所以我们的每次访问都需要进行伪装，伪装成学生这样才能访问服务器里的信息。<br>默认使用requests模块发送请求: ‘User-Agent’: ‘python-requests/2.18.1’, 百度服务器就认为这是一个爬虫,就不给你真正的页面.</p>
<p>在requests发送请求指定headers的格式 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">requests.get(r<span class="string">"http://www.baidu.com"</span>, headers=headers)</span><br></pre></td></tr></table></figure>

<p>上面则是携带了headers请求头进行了一次伪装请求百度</p>
<h2 id="爬取愁事百科"><a href="#爬取愁事百科" class="headerlink" title="爬取愁事百科"></a>爬取愁事百科</h2><p>完整源码（仅供参考）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">from lxml import etree</span><br><span class="line">import requests,json</span><br><span class="line">class ChouShi():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    def get_list(self,html):</span><br><span class="line">        list_info = []</span><br><span class="line">        htmls = etree.HTML(html.text)</span><br><span class="line">        ret_list = htmls.xpath(<span class="string">"//div[@class='recommend-article']//li"</span>)</span><br><span class="line">        <span class="keyword">for</span> list <span class="keyword">in</span> ret_list:</span><br><span class="line">            title = list.xpath(<span class="string">".//div[@class='recmd-right']/a/text()"</span>)</span><br><span class="line">            img = list.xpath(<span class="string">".//div[@class='recmd-detail clearfix']//a/img/@src"</span>)</span><br><span class="line">            name = list.xpath(<span class="string">".//div[@class='recmd-detail clearfix']//a/span/text()"</span>)</span><br><span class="line">            punchline = list.xpath(<span class="string">".//div[@class='recmd-num']/span[1]/text()"</span>)  <span class="comment">#好笑</span></span><br><span class="line">            comment = list.xpath(<span class="string">".//div[@class='recmd-num']/span[4]/text()"</span>)  <span class="comment">#评论</span></span><br><span class="line">            list_info.append(&#123;<span class="string">"标题"</span>:title,<span class="string">"图片"</span>:img,<span class="string">"匿名"</span>:name,<span class="string">"好笑量"</span>:punchline,<span class="string">"评论量"</span>:comment&#125;)</span><br><span class="line">        <span class="built_in">return</span> list_info</span><br><span class="line"></span><br><span class="line">    def urls(self):</span><br><span class="line">        url_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(13):</span><br><span class="line">            url = <span class="string">'https://www.qiushibaike.com/8hr/page/%s/'</span> % (i + 1)</span><br><span class="line">            url_list.append(url)</span><br><span class="line">        <span class="built_in">return</span> url_list</span><br><span class="line"></span><br><span class="line">    def save(self,lists):</span><br><span class="line">        json_str = json.dumps(lists,indent=4,ensure_ascii=False) <span class="comment">#设置写入的数据不能是二进制</span></span><br><span class="line">        with open(<span class="string">'./chou事百科.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>)as f:</span><br><span class="line">            f.write(json_str)</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        url = self.urls()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> url:</span><br><span class="line">            html = requests.get(i, headers=self.headers)</span><br><span class="line">            lists = self.get_list(html)</span><br><span class="line">            self.save(lists)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    choushi = ChouShi()</span><br><span class="line">    choushi.run()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/22/hexo基本操作与部署/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/22/hexo基本操作与部署/" class="post-title-link" itemprop="url">hexo基本操作与部署</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-22 19:43:56" itemprop="dateCreated datePublished" datetime="2019-07-22T19:43:56+08:00">2019-07-22</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-07-25 18:02:57" itemprop="dateModified" datetime="2019-07-25T18:02:57+08:00">2019-07-25</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="hexo-基本操作"><a href="#hexo-基本操作" class="headerlink" title="hexo 基本操作"></a>hexo 基本操作</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>启动hexo服务</p>
<p>运行成功后的效果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure>

<p>访问<a href="http://localhost:4000就可以看到自己的博客" target="_blank" rel="noopener">http://localhost:4000就可以看到自己的博客</a></p>
<h2 id="常用的hexo命令集"><a href="#常用的hexo命令集" class="headerlink" title="常用的hexo命令集"></a>常用的hexo命令集</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate  简写  hexo g</span><br></pre></td></tr></table></figure>

<p>生成静态文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy  简写  hexo d</span><br></pre></td></tr></table></figure>

<p>部署网页，网页上线后则通过这个命令进行上传文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br></pre></td></tr></table></figure>

<p>清除缓存文件</p>
<h2 id="hexo更新数据"><a href="#hexo更新数据" class="headerlink" title="hexo更新数据"></a>hexo更新数据</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo g</span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>

<p>重新运行浏览器进入个人博客</p>
<h2 id="hexo部署的坑区"><a href="#hexo部署的坑区" class="headerlink" title="hexo部署的坑区"></a>hexo部署的坑区</h2><p>文章参考：<br>推荐一个个人博客：<a href="https://blog.csdn.net/liuyongshun2/article/details/54629087" target="_blank" rel="noopener">https://blog.csdn.net/liuyongshun2/article/details/54629087</a></p>
<h2 id="hexo的命令大全"><a href="#hexo的命令大全" class="headerlink" title="hexo的命令大全"></a>hexo的命令大全</h2><p>文章参考：<br><a href="https://hexo.io/zh-cn/docs/commands.html" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/commands.html</a></p>
<h2 id="搭建个人博客视频（hexo与git的使用）"><a href="#搭建个人博客视频（hexo与git的使用）" class="headerlink" title="搭建个人博客视频（hexo与git的使用）"></a>搭建个人博客视频（hexo与git的使用）</h2><p>文章参考：<br>bibi视频:<a href="https://www.bilibili.com/video/av60124681" target="_blank" rel="noopener">https://www.bilibili.com/video/av60124681</a></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/22/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ssc">
      <meta itemprop="description" content="关于ssc学习python的艰辛之旅">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Welcome to ssc bolg !">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/22/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-07-22 16:28:27" itemprop="dateCreated datePublished" datetime="2019-07-22T16:28:27+08:00">2019-07-22</time>
            </span>
          

          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
  <p class="site-author-name" itemprop="name">ssc</p>
  <div class="site-description motion-element" itemprop="description">关于ssc学习python的艰辛之旅</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">Artikel</span>
        </a>
      </div>
    

    

    
  </nav>













          
          
        </div>
      </div>

      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
        <title>Live2D！把可爱的看板娘扑捉到你的博客去吧！</title>
          <link rel="stylesheet" href="/live2d/css/live2d.css">
      <div id="landlord">
          <div class="message" style="opacity:0"></div>
          <canvas id="live2d" width="280" height="250" class="live2d"></canvas>
          <div class="hide-button">隐藏</div>
      </div>
      <script type="text/javascript" src="https://cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
      <script type="text/javascript">
          var message_Path = '/live2d/'
          var home_Path = 'https://www.baidu.com/'
      </script>
      <script type="text/javascript" src="/live2d/js/live2d.js"></script>
      <script type="text/javascript" src="/live2d/js/message.js"></script>
      <script type="text/javascript">
          loadlive2d("live2d", "/live2d/model/tia/model.json");
      </script>
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ssc</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Design – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    

  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


















  
  









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>



  

  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  


  






























<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>








  

</body>
</html>
